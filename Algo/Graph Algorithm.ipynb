{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afb18cfe-a04b-4656-bf44-82a591d37773",
   "metadata": {},
   "source": [
    "# Breadth-first search¶\r\n",
    "Breadth first search is one of the basic and essential searching algorithms on graphs.\r\n",
    "\r\n",
    "As a result of how the algorithm works, the path found by breadth first search to any node is the shortest path to that node, i.e the path that contains the smallest number of edges in unweighted graphs.\r\n",
    "\r\n",
    "The algorithm works in  \r\n",
    "$O(n + m)$  time, where  \r\n",
    "$n$  is number of vertices and  \r\n",
    "$m$  is the number of edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71923f02-98b8-4691-baa1-0683adfd3ae2",
   "metadata": {},
   "source": [
    "## Description of the algorithm¶\r\n",
    "The algorithm takes as input an unweighted graph and the id of the source vertex  \r\n",
    "$s$ . The input graph can be directed or undirected, it does not matter to the algorithm.\r\n",
    "\r\n",
    "The algorithm can be understood as a fire spreading on the graph: at the zeroth step only the source  \r\n",
    "$s$  is on fire. At each step, the fire burning at each vertex spreads to all of its neighbors. In one iteration of the algorithm, the \"ring of fire\" is expanded in width by one unit (hence the name of the algorithm).\r\n",
    "\r\n",
    "More precisely, the algorithm can be stated as follows: Create a queue  \r\n",
    "$q$  which will contain the vertices to be processed and a Boolean array  \r\n",
    "$used[]$  which indicates for each vertex, if it has been lit (or visited) or not.\r\n",
    "\r\n",
    "Initially, push the source  \r\n",
    "$s$  to the queue and set  \r\n",
    "$used[s] = true$ , and for all other vertices  \r\n",
    "$v$  set  \r\n",
    "$used[v] = false$ . Then, loop until the queue is empty and in each iteration, pop a vertex from the front of the queue. Iterate through all the edges going out of this vertex and if some of these edges go to vertices that are not already lit, set them on fire and place them in the queue.\r\n",
    "\r\n",
    "As a result, when the queue is empty, the \"ring of fire\" contains all vertices reachable from the source  \r\n",
    "$s$ , with each vertex reached in the shortest possible way. You can also calculate the lengths of the shortest paths (which just requires maintaining an array of path lengths  \r\n",
    "$d[]$ ) as well as save information to restore all of these shortest paths (for this, it is necessary to maintain an array of \"parents\"  \r\n",
    "$p[]$ , which stores for each vertex the vertex from which we reached it).\r\n",
    "\r\n",
    "Implementation¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3baf28-e0fa-4f18-9f2a-62bc0cc49fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector<vector<int>> adj;  // adjacency list representation\r\n",
    "int n; // number of nodes\r\n",
    "int s; // source vertex\r\n",
    "\r\n",
    "queue<int> q;\r\n",
    "vector<bool> used(n);\r\n",
    "vector<int> d(n), p(n);\r\n",
    "\r\n",
    "q.push(s);\r\n",
    "used[s] = true;\r\n",
    "p[s] = -1;\r\n",
    "while (!q.empty()) {\r\n",
    "    int v = q.front();\r\n",
    "    q.pop();\r\n",
    "    for (int u : adj[v]) {\r\n",
    "        if (!used[u]) {\r\n",
    "            used[u] = true;\r\n",
    "            q.push(u);\r\n",
    "            d[u] = d[v] + 1;\r\n",
    "            p[u] = v;\r\n",
    "        }\r\n",
    "    }\r\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f7482b-a2f2-4ad3-be21-4b9cb66a199b",
   "metadata": {},
   "source": [
    "If we have to restore and display the shortest path from the source to some vertex  \n",
    "$u$ , it can be done in the following manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57105c54-2a3a-41c2-ad24-92268ffa2999",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (!used[u]) {\n",
    "    cout << \"No path!\";\n",
    "} else {\n",
    "    vector<int> path;\n",
    "    for (int v = u; v != -1; v = p[v])\n",
    "        path.push_back(v);\n",
    "    reverse(path.begin(), path.end());\n",
    "    cout << \"Path: \";\n",
    "    for (int v : path)\n",
    "        cout << v << \" \";\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85d52a-bb0e-45f2-b442-7b927b327969",
   "metadata": {},
   "source": [
    "# Depth First Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69482dea-e415-4ba4-a11d-7926cc72e3fb",
   "metadata": {},
   "source": [
    "Depth First Search is one of the main graph algorithms.\n",
    "\n",
    "Depth First Search finds the lexicographical first path in the graph from a source vertex  \n",
    "$u$  to each vertex. Depth First Search will also find the shortest paths in a tree (because there only exists one simple path), but on general graphs this is not the case.\n",
    "\n",
    "The algorithm works in  \n",
    "$O(m + n)$  time where  \n",
    "$n$  is the number of vertices and  \n",
    "$m$  is the number of edges.\n",
    "\n",
    "Description of the algorithm¶\n",
    "The idea behind DFS is to go as deep into the graph as possible, and backtrack once you are at a vertex without any unvisited adjacent vertices.\n",
    "\n",
    "It is very easy to describe / implement the algorithm recursively: We start the search at one vertex. After visiting a vertex, we further perform a DFS for each adjacent vertex that we haven't visited before. This way we visit all vertices that are reachable from the starting vertex.\n",
    "\n",
    "For more details check out the implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270eb2be-64c3-4d7b-914a-8891a35ccf20",
   "metadata": {},
   "source": [
    "Classification of edges of a graph¶\n",
    "We can classify the edges using the entry and exit time of the end nodes  \n",
    "$u$  and  \n",
    "$v$  of the edges  \n",
    "$(u,v)$ . These classifications are often used for problems like finding bridges and finding articulation points.\n",
    "\n",
    "We perform a DFS and classify the encountered edges using the following rules:\n",
    "\n",
    "If  \n",
    "$v$  is not visited:\n",
    "\n",
    "Tree Edge - If  \n",
    "$v$  is visited after  \n",
    "$u$  then edge  \n",
    "$(u,v)$  is called a tree edge. In other words, if  \n",
    "$v$  is visited for the first time and  \n",
    "$u$  is currently being visited then  \n",
    "$(u,v)$  is called tree edge. These edges form a DFS tree and hence the name tree edges.\n",
    "If  \n",
    "$v$  is visited before  \n",
    "$u$ :\n",
    "\n",
    "Back edges - If  \n",
    "$v$  is an ancestor of  \n",
    "$u$ , then the edge  \n",
    "$(u,v)$  is a back edge.  \n",
    "$v$  is an ancestor exactly if we already entered  \n",
    "$v$ , but not exited it yet. Back edges complete a cycle as there is a path from ancestor  \n",
    "$v$  to descendant  \n",
    "$u$  (in the recursion of DFS) and an edge from descendant  \n",
    "$u$  to ancestor  \n",
    "$v$  (back edge), thus a cycle is formed. Cycles can be detected using back edges.\n",
    "\n",
    "Forward Edges - If  \n",
    "$v$  is a descendant of  \n",
    "$u$ , then edge  \n",
    "$(u, v)$  is a forward edge. In other words, if we already visited and exited  \n",
    "$v$  and  \n",
    "$\\text{entry}[u] < \\text{entry}[v]$  then the edge  \n",
    "$(u,v)$  forms a forward edge.\n",
    "\n",
    "Cross Edges: if  \n",
    "$v$  is neither an ancestor or descendant of  \n",
    "$u$ , then edge  \n",
    "$(u, v)$  is a cross edge. In other words, if we already visited and exited  \n",
    "$v$  and  \n",
    "$\\text{entry}[u] > \\text{entry}[v]$  then  \n",
    "$(u,v)$  is a cross edge.\n",
    "Note: Forward edges and cross edges only exist in directed graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae08fe-ced7-46ab-827c-c6c443bfe9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector<vector<int>> adj; // graph represented as an adjacency list\n",
    "int n; // number of vertices\n",
    "\n",
    "vector<bool> visited;\n",
    "\n",
    "void dfs(int v) {\n",
    "    visited[v] = true;\n",
    "    for (int u : adj[v]) {\n",
    "        if (!visited[u])\n",
    "            dfs(u);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c326cf-328f-4ab2-99bf-14b53d6d8ea1",
   "metadata": {},
   "source": [
    "This is the most simple implementation of Depth First Search. As described in the applications it might be useful to also compute the entry and exit times and vertex color. We will color all vertices with the color 0, if we haven't visited them, with the color 1 if we visited them, and with the color 2, if we already exited the vertex.\n",
    "Here is a generic implementation that additionally computes those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4614e7e1-625a-4ffa-b35d-60a245eddef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector<vector<int>> adj; // graph represented as an adjacency list\n",
    "int n; // number of vertices\n",
    "\n",
    "vector<int> color;\n",
    "\n",
    "vector<int> time_in, time_out;\n",
    "int dfs_timer = 0;\n",
    "\n",
    "void dfs(int v) {\n",
    "    time_in[v] = dfs_timer++;\n",
    "    color[v] = 1;\n",
    "    for (int u : adj[v])\n",
    "        if (color[u] == 0)\n",
    "            dfs(u);\n",
    "    color[v] = 2;\n",
    "    time_out[v] = dfs_timer++;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b33846-90a6-4fd8-8935-5be65147807a",
   "metadata": {},
   "source": [
    "# Search for connected components in a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef60426-2544-4f77-aeb1-ab9da8446941",
   "metadata": {},
   "source": [
    "Given an undirected graph  \n",
    "$G$  with  \n",
    "$n$  nodes and  \n",
    "$m$  edges. We are required to find in it all the connected components, i.e, several groups of vertices such that within a group each vertex can be reached from another and no path exists between different groups.\n",
    "\n",
    "An algorithm for solving the problem¶\n",
    "To solve the problem, we can use Depth First Search or Breadth First Search.\n",
    "\n",
    "In fact, we will be doing a series of rounds of DFS: The first round will start from first node and all the nodes in the first connected component will be traversed (found). Then we find the first unvisited node of the remaining nodes, and run Depth First Search on it, thus finding a second connected component. And so on, until all the nodes are visited.\n",
    "\n",
    "The total asymptotic running time of this algorithm is  \n",
    "$O(n + m)$  : In fact, this algorithm will not run on the same vertex twice, which means that each edge will be seen exactly two times (at one end and at the other end).\n",
    "\n",
    "Implementation¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f27ac72-c45c-4036-9575-47cf83ff74ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "int n;\n",
    "vector<vector<int>> adj;\n",
    "vector<bool> used;\n",
    "vector<int> comp;\n",
    "\n",
    "void dfs(int v) {\n",
    "    used[v] = true ;\n",
    "    comp.push_back(v);\n",
    "    for (int u : adj[v]) {\n",
    "        if (!used[u])\n",
    "            dfs(u);\n",
    "    }\n",
    "}\n",
    "\n",
    "void find_comps() {\n",
    "    fill(used.begin(), used.end(), 0);\n",
    "    for (int v = 0; v < n; ++v) {\n",
    "        if (!used[v]) {\n",
    "            comp.clear();\n",
    "            dfs(v);\n",
    "            cout << \"Component:\" ;\n",
    "            for (int u : comp)\n",
    "                cout << ' ' << u;\n",
    "            cout << endl ;\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabdde30-b015-440c-a162-184aa70ca31e",
   "metadata": {},
   "source": [
    "The most important function that is used is find_comps() which finds and displays connected components of the graph.\n",
    "\n",
    "The graph is stored in adjacency list representation, i.e adj[v] contains a list of vertices that have edges from the vertex v.\n",
    "\n",
    "Vector comp contains a list of nodes in the current connected component.\n",
    "\n",
    "Iterative implementation of the code¶\n",
    "Deeply recursive functions are in general bad. Every single recursive call will require a little bit of memory in the stack, and per default programs only have a limited amount of stack space. So when you do a recursive DFS over a connected graph with millions of nodes, you might run into stack overflows.\n",
    "\n",
    "It is always possible to translate a recursive program into an iterative program, by manually maintaining a stack data structure. Since this data structure is allocated on the heap, no stack overflow will occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4410284b-e65f-4919-bb16-c22b9caa66e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "int n;\n",
    "vector<vector<int>> adj;\n",
    "vector<bool> used;\n",
    "vector<int> comp;\n",
    "\n",
    "void dfs(int v) {\n",
    "    stack<int> st;\n",
    "    st.push(v);\n",
    "\n",
    "    while (!st.empty()) {\n",
    "        int curr = st.top();\n",
    "        st.pop();\n",
    "        if (!used[curr]) {\n",
    "            used[curr] = true;\n",
    "            comp.push_back(curr);\n",
    "            for (int i = adj[curr].size() - 1; i >= 0; i--) {\n",
    "                st.push(adj[curr][i]);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "void find_comps() {\n",
    "    fill(used.begin(), used.end(), 0);\n",
    "    for (int v = 0; v < n ; ++v) {\n",
    "        if (!used[v]) {\n",
    "            comp.clear();\n",
    "            dfs(v);\n",
    "            cout << \"Component:\" ;\n",
    "            for (int u : comp)\n",
    "                cout << ' ' << u;\n",
    "            cout << endl ;\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571b4203-c76b-4dfd-b13c-5ab12f20707b",
   "metadata": {},
   "source": [
    "# Finding bridges in a graph in  $O(N+M)$ ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2275455-8ccc-4bc3-8a6b-7a9d277277a5",
   "metadata": {},
   "source": [
    "We are given an undirected graph. A bridge is defined as an edge which, when removed, makes the graph disconnected (or more precisely, increases the number of connected components in the graph). The task is to find all bridges in the given graph.\r\n",
    "\r\n",
    "Informally, the problem is formulated as follows: given a map of cities connected with roads, find all \"important\" roads, i.e. roads which, when removed, cause disappearance of a path between some pair of cities.\r\n",
    "\r\n",
    "The algorithm described here is based on depth first search and has  \r\n",
    "$O(N+M)$  complexity, where  \r\n",
    "$N$  is the number of vertices and  \r\n",
    "$M$  is the number of edges in the graph.\r\n",
    "\r\n",
    "Note that there is also the article Finding Bridges Online - unlike the offline algorithm described here, the online algorithm is able to maintain the list of all bridges in a changing graph (assuming that the only type of change is addition of new edges).\r\n",
    "\r\n",
    "Algorithm¶\r\n",
    "Pick an arbitrary vertex of the graph  \r\n",
    "$root$  and run depth first search from it. Note the following fact (which is easy to prove):\r\n",
    "\r\n",
    "Let's say we are in the DFS, looking through the edges starting from vertex  \r\n",
    "$v$ . The current edge  \r\n",
    "$(v, to)$  is a bridge if and only if none of the vertices  \r\n",
    "$to$  and its descendants in the DFS traversal tree has a back-edge to vertex  \r\n",
    "$v$  or any of its ancestors. Indeed, this condition means that there is no other way from  \r\n",
    "$v$  to  \r\n",
    "$to$  except for edge  \r\n",
    "$(v, to)$ .\r\n",
    "Now we have to learn to check this fact for each vertex efficiently. We'll use \"time of entry into node\" computed by the depth first search.\r\n",
    "\r\n",
    "So, let  \r\n",
    "$tin[v]$  denote entry time for node  \r\n",
    "$v$ . We introduce an array  \r\n",
    "$low$  which will let us check the fact for each vertex  \r\n",
    "$v$ .  \r\n",
    "$low[v]$  is the minimum of  \r\n",
    "$tin[v]$ , the entry times  \r\n",
    "$tin[p]$  for each node  \r\n",
    "$p$  that is connected to node  \r\n",
    "$v$  via a back-edge  \r\n",
    "$(v, p)$  and the values of  \r\n",
    "$low[to]$  for each vertex  \r\n",
    "$to$  which is a direct descendant of  \r\n",
    "$v$  in the DFS tree:\r\n",
    "\r\n",
    " \r\n",
    " \r\n",
    " \r\n",
    "$$low[v] = \\min \\begin{cases} tin[v] \\\\ tin[p]& \\text{ for all }p\\text{ for which }(v, p)\\text{ is a back edge} \\\\ low[to]& \\text{ for all }to\\text{ for which }(v, to)\\text{ is a tree edge} \\end{cases}$$ \r\n",
    "Now, there is a back edge from vertex  \r\n",
    "$v$  or one of its descendants to one of its ancestors if and only if vertex  \r\n",
    "$v$  has a child  \r\n",
    "$to$  for which  \r\n",
    "$low[to] \\leq tin[v]$ . If  \r\n",
    "$low[to] = tin[v]$ , the back edge comes directly to  \r\n",
    "$v$ , otherwise it comes to one of the ancestors of  \r\n",
    "$v$ .\r\n",
    "\r\n",
    "Thus, the current edge  \r\n",
    "$(v, to)$  in the DFS tree is a bridge if and only if  \r\n",
    "$low[to] > tin[v]$ .\r\n",
    "\r\n",
    "Implementation¶\r\n",
    "The implementation needs to distinguish three cases: when we go down the edge in DFS tree, when we find a back edge to an ancestor of the vertex and when we return to a parent of the vertex. These are the cases:\r\n",
    "\r\n",
    " \r\n",
    "$visited[to] = false$  - the edge is part of DFS tree;\r\n",
    " \r\n",
    "$visited[to] = true$  &&  \r\n",
    "$to \\neq parent$  - the edge is back edge to one of the ancestors;\r\n",
    " \r\n",
    "$to = parent$  - the edge leads back to parent in DFS tree.\r\n",
    "To implement this, we need a depth first search function which accepts the parent vertex of the current node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c24d24-a07d-466c-bc98-6c99821a5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "int n; // number of nodes\n",
    "vector<vector<int>> adj; // adjacency list of graph\n",
    "\n",
    "vector<bool> visited;\n",
    "vector<int> tin, low;\n",
    "int timer;\n",
    "\n",
    "void dfs(int v, int p = -1) {\n",
    "    visited[v] = true;\n",
    "    tin[v] = low[v] = timer++;\n",
    "    for (int to : adj[v]) {\n",
    "        if (to == p) continue;\n",
    "        if (visited[to]) {\n",
    "            low[v] = min(low[v], tin[to]);\n",
    "        } else {\n",
    "            dfs(to, v);\n",
    "            low[v] = min(low[v], low[to]);\n",
    "            if (low[to] > tin[v])\n",
    "                IS_BRIDGE(v, to);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "void find_bridges() {\n",
    "    timer = 0;\n",
    "    visited.assign(n, false);\n",
    "    tin.assign(n, -1);\n",
    "    low.assign(n, -1);\n",
    "    for (int i = 0; i < n; ++i) {\n",
    "        if (!visited[i])\n",
    "            dfs(i);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3b7212-2adc-4272-9ae1-ed0cc1a125d3",
   "metadata": {},
   "source": [
    "Main function is find_bridges; it performs necessary initialization and starts depth first search in each connected component of the graph.\n",
    "\n",
    "Function IS_BRIDGE(a, b) is some function that will process the fact that edge  \n",
    "$(a, b)$  is a bridge, for example, print it.\n",
    "\n",
    "Note that this implementation malfunctions if the graph has multiple edges, since it ignores them. Of course, multiple edges will never be a part of the answer, so IS_BRIDGE can check additionally that the reported bridge is not a multiple edge. Alternatively it's possible to pass to dfs the index of the edge used to enter the vertex instead of the parent vertex (and store the indices of all vertices)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049de549-aa41-4403-852f-99ebf71b2526",
   "metadata": {},
   "source": [
    "# Finding strongly connected components / Building condensation graph¶\r\n",
    "Definitions¶\r\n",
    "You are given a directed graph  \r\n",
    "$G$  with vertices  \r\n",
    "$V$  and edges  \r\n",
    "$E$ . It is possible that there are loops and multiple edges. Let's denote  \r\n",
    "$n$  as number of vertices and  \r\n",
    "$m$  as number of edges in  \r\n",
    "$G$ .\r\n",
    "\r\n",
    "Strongly connected component is a maximal subset of vertices  \r\n",
    "$C$  such that any two vertices of this subset are reachable from each other, i.e. for any  \r\n",
    "$u, v \\in C$ :\r\n",
    "\r\n",
    " \r\n",
    "$$u \\mapsto v, v \\mapsto u$$ \r\n",
    "where  \r\n",
    "$\\mapsto$  means reachability, i.e. existence of the path from first vertex to the second.\r\n",
    "\r\n",
    "It is obvious, that strongly connected components do not intersect each other, i.e. this is a partition of all graph vertices. Thus we can give a definition of condensation graph  \r\n",
    "$G^{SCC}$  as a graph containing every strongly connected component as one vertex. Each vertex of the condensation graph corresponds to the strongly connected component of graph  \r\n",
    "$G$ . There is an oriented edge between two vertices  \r\n",
    "$C_i$  and  \r\n",
    "$C_j$  of the condensation graph if and only if there are two vertices  \r\n",
    "$u \\in C_i, v \\in C_j$  such that there is an edge in initial graph, i.e.  \r\n",
    "$(u, v) \\in E$ .\r\n",
    "\r\n",
    "The most important property of the condensation graph is that it is acyclic. Indeed, suppose that there is an edge between  \r\n",
    "$C$  and  \r\n",
    "$C'$ , let's prove that there is no edge from  \r\n",
    "$C'$  to  \r\n",
    "$C$ . Suppose that  \r\n",
    "$C' \\mapsto C$ . Then there are two vertices  \r\n",
    "$u' \\in C$  and  \r\n",
    "$v' \\in C'$  such that  \r\n",
    "$v' \\mapsto u'$ . But since  \r\n",
    "$u$  and  \r\n",
    "$u'$  are in the same strongly connected component then there is a path between them; the same for  \r\n",
    "$v$  and  \r\n",
    "$v'$ . As a result, if we join these paths we have that  \r\n",
    "$v \\mapsto u$  and at the same time  \r\n",
    "$u \\mapsto v$ . Therefore  \r\n",
    "$u$  and  \r\n",
    "$v$  should be at the same strongly connected component, so this is contradiction. This completes the proof.\r\n",
    "\r\n",
    "The algorithm described in the next section extracts all strongly connected components in a given graph. It is qu\n",
    "i## te easy to build a condensat\n",
    "on graph then.\r\n",
    "\r\n",
    "Description of the algorithm¶\r\n",
    "Described algorithm was independently suggested by Kosaraju and Sharir at 1979. This is an easy-to-implement algorithm based on two series of depth first search, and working for  \r\n",
    "$O(n + m)$  time.\r\n",
    "\r\n",
    "On the first step of the algorithm we are doing sequence of depth first searches, visiting the entire graph. We start at each vertex of the graph and run a depth first search from every non-visited vertex. For each vertex we are keeping track of exit time  \r\n",
    "$tout[v]$ . These exit times have a key role in an algorithm and this role is expressed in next theorem.\r\n",
    "\r\n",
    "First, let's make notations: let's define exit time  \r\n",
    "$tout[C]$  from the strongly connected component  \r\n",
    "$C$  as maximum of values  \r\n",
    "$tout[v]$  by all  \r\n",
    "$v \\in C$ . Besides, during the proof of the theorem we will mention entry times  \r\n",
    "$tin[v]$  in each vertex and in the same way consider  \r\n",
    "$tin[C]$  for each strongly connected component  \r\n",
    "$C$  as minimum of values  \r\n",
    "$tin[v]$  by all  \r\n",
    "$v \\in C$ .\r\n",
    "\r\n",
    "Theorem. Let  \r\n",
    "$C$  and  \r\n",
    "$C'$  are two different strongly connected components and there is an edge  \r\n",
    "$(C, C')$  in a condensation graph between these two vertices. Then  \r\n",
    "$tout[C] > tout[C']$ .\r\n",
    "\r\n",
    "There are two main different cases at the proof depending on which component will be visited by depth first search first, i.e. depending on difference between  \r\n",
    "$tin[C]$  and  \r\n",
    "$tin[C']$ :\r\n",
    "\r\n",
    "The component  \r\n",
    "$C$  was reached first. It means that depth first search comes at some vertex  \r\n",
    "$v$  of component  \r\n",
    "$C$  at some moment, but all other vertices of components  \r\n",
    "$C$  and  \r\n",
    "$C'$  were not visited yet. By condition there is an edge  \r\n",
    "$(C, C')$  in a condensation graph, so not only the entire component  \r\n",
    "$C$  is reachable from  \r\n",
    "$v$  but the whole component  \r\n",
    "$C'$  is reachable as well. It means that depth first search that is running from vertex  \r\n",
    "$v$  will visit all vertices of components  \r\n",
    "$C$  and  \r\n",
    "$C'$ , so they will be descendants for  \r\n",
    "$v$  in a depth first search tree, i.e. for each vertex  \r\n",
    "$u \\in C \\cup C', u \\ne v$  we have that  \r\n",
    "$tout[v] > tout[u]$ , as we claimed.\r\n",
    "\r\n",
    "Assume that component  \r\n",
    "$C'$  was visited first. Similarly, depth first search comes at some vertex  \r\n",
    "$v$  of component  \r\n",
    "$C'$  at some moment, but all other vertices of components  \r\n",
    "$C$  and  \r\n",
    "$C'$  were not visited yet. But by condition there is an edge  \r\n",
    "$(C, C')$  in the condensation graph, so, because of acyclic property of condensation graph, there is no back path from  \r\n",
    "$C'$  to  \r\n",
    "$C$ , i.e. depth first search from vertex  \r\n",
    "$v$  will not reach vertices of  \r\n",
    "$C$ . It means that vertices of  \r\n",
    "$C$  will be visited by depth first search later, so  \r\n",
    "$tout[C] > tout[C']$ . This completes the proof.\r\n",
    "\r\n",
    "Proved theorem is the base of algorithm for finding strongly connected components. It follows that any edge  \r\n",
    "$(C, C')$  in condensation graph comes from a component with a larger value of  \r\n",
    "$tout$  to component with a smaller value.\r\n",
    "\r\n",
    "If we sort all vertices  \r\n",
    "$v \\in V$  in decreasing order of their exit time  \r\n",
    "$tout[v]$  then the first vertex  \r\n",
    "$u$  is going to be a vertex belonging to \"root\" strongly connected component, i.e. a vertex that has no incoming edges in the condensation graph. Now we want to run such search from this vertex  \r\n",
    "$u$  so that it will visit all vertices in this strongly connected component, but not others; doing so, we can gradually select all strongly connected components: let's remove all vertices corresponding to the first selected component, and then let's find a vertex with the largest value of  \r\n",
    "$tout$ , and run this search from it, and so on.\r\n",
    "\r\n",
    "Let's consider transposed graph  \r\n",
    "$G^T$ , i.e. graph received from  \r\n",
    "$G$  by reversing the direction of each edge. Obviously, this graph will have the same strongly connected components as the initial graph. Moreover, the condensation graph  \r\n",
    "$G^{SCC}$  will also get transposed. It means that there will be no edges from our \"root\" component to other components.\r\n",
    "\r\n",
    "Thus, for visiting the whole \"root\" strongly connected component, containing vertex  \r\n",
    "$v$ , is enough to run search from vertex  \r\n",
    "$v$  in graph  \r\n",
    "$G^T$ . This search will visit all vertices of this strongly connected component and only them. As was mentioned before, we can remove these vertices from the graph then, and find the next vertex with a maximal value of  \r\n",
    "$tout[v]$  and run search in transposed graph from it, and so on.\r\n",
    "\r\n",
    "Thus, we built next algorithm for selecting strongly connected components:\r\n",
    "\r\n",
    "1st step. Run sequence of depth first search of graph  \r\n",
    "$G$  which will return vertices with increasing exit time  \r\n",
    "$tout$ , i.e. some list  \r\n",
    "$order$ .\r\n",
    "\r\n",
    "2nd step. Build transposed graph  \r\n",
    "$G^T$ . Run a series of depth (breadth) first searches in the order determined by list  \r\n",
    "$order$  (to be exact in reverse order, i.e. in decreasing order of exit times). Every set of vertices, reached after the next search, will be the next strongly connected component.\r\n",
    "\r\n",
    "Algorithm asymptotic is  \r\n",
    "$O(n + m)$ , because it is just two depth (breadth) first searches.\r\n",
    "\r\n",
    "Finally, it is appropriate to mention topological sort here. First of all, step 1 of the algorithm represents reversed topological sort of graph  \r\n",
    "$G$  (actually this is exactly what vertices' sort by exit time means). Secondly, the algorithm's scheme generates strongly connected components by decreasing order of their exit times, thus it generates components - vertices of condensation graph - in topological sort order.\r\n",
    "\r\n",
    "Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a4801d-7072-4e53-b812-75c68246b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector<vector<int>> adj, adj_rev;\n",
    "vector<bool> used;\n",
    "vector<int> order, component;\n",
    "\n",
    "void dfs1(int v) {\n",
    "    used[v] = true;\n",
    "\n",
    "    for (auto u : adj[v])\n",
    "        if (!used[u])\n",
    "            dfs1(u);\n",
    "\n",
    "    order.push_back(v);\n",
    "}\n",
    "\n",
    "void dfs2(int v) {\n",
    "    used[v] = true;\n",
    "    component.push_back(v);\n",
    "\n",
    "    for (auto u : adj_rev[v])\n",
    "        if (!used[u])\n",
    "            dfs2(u);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int n;\n",
    "    // ... read n ...\n",
    "\n",
    "    for (;;) {\n",
    "        int a, b;\n",
    "        // ... read next directed edge (a,b) ...\n",
    "        adj[a].push_back(b);\n",
    "        adj_rev[b].push_back(a);\n",
    "    }\n",
    "\n",
    "    used.assign(n, false);\n",
    "\n",
    "    for (int i = 0; i < n; i++)\n",
    "        if (!used[i])\n",
    "            dfs1(i);\n",
    "\n",
    "    used.assign(n, false);\n",
    "    reverse(order.begin(), order.end());\n",
    "\n",
    "    for (auto v : order)\n",
    "        if (!used[v]) {\n",
    "            dfs2 (v);\n",
    "\n",
    "            // ... processing next component ...\n",
    "\n",
    "            component.clear();\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc71af58-56ff-4f79-a828-3d081646a5cd",
   "metadata": {},
   "source": [
    "Here,  \n",
    "$g$  is graph,  \n",
    "$gr$  is transposed graph. Function  \n",
    "$dfs1$  implements depth first search on graph  \n",
    "$G$ , function  \n",
    "$dfs2$  - on transposed graph  \n",
    "$G^T$ . Function  \n",
    "$dfs1$  fills the list  \n",
    "$order$  with vertices in increasing order of their exit times (actually, it is making a topological sort). Function  \n",
    "$dfs2$  stores all reached vertices in list  \n",
    "$component$ , that is going to store next strongly connected component after each run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b49af-20c0-4cfc-b8b0-e11a35b59a38",
   "metadata": {},
   "source": [
    "## Condensation Graph Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a19c7-5ba7-45fa-b4b3-5c602c897362",
   "metadata": {},
   "outputs": [],
   "source": [
    "// continuing from previous code\n",
    "\n",
    "vector<int> roots(n, 0);\n",
    "vector<int> root_nodes;\n",
    "vector<vector<int>> adj_scc(n);\n",
    "\n",
    "for (auto v : order)\n",
    "    if (!used[v]) {\n",
    "        dfs2(v);\n",
    "\n",
    "        int root = component.front();\n",
    "        for (auto u : component) roots[u] = root;\n",
    "        root_nodes.push_back(root);\n",
    "\n",
    "        component.clear();\n",
    "    }\n",
    "\n",
    "\n",
    "for (int v = 0; v < n; v++)\n",
    "    for (auto u : adj[v]) {\n",
    "        int root_v = roots[v],\n",
    "            root_u = roots[u];\n",
    "\n",
    "        if (root_u != root_v)\n",
    "            adj_scc[root_v].push_back(root_u);\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21accc5a-b4d6-4439-9a43-badc05a8d9e9",
   "metadata": {},
   "source": [
    "Here, we have selected the root of each component as the first node in its list. This node will represent its entire SCC in the condensation graph. roots[v] indicates the root node for the SCC to which node v belongs. root_nodes is the list of all root nodes (one per component) in the condensation graph.\n",
    "\n",
    "adj_scc is the adjacency list of the root_nodes. We can now traverse on adj_scc as our condensation graph, using only those nodes which belong to root_nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cca6e15-a26a-4bbb-b542-c698fe383edc",
   "metadata": {},
   "source": [
    "# Dijkstra Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cc383f-2e11-4641-9cbf-377f9c870336",
   "metadata": {},
   "source": [
    "You are given a directed or undirected weighted graph with  \n",
    "$n$  vertices and  \n",
    "$m$  edges. The weights of all edges are non-negative. You are also given a starting vertex  \n",
    "$s$ . This article discusses finding the lengths of the shortest paths from a starting vertex  \n",
    "$s$  to all other vertices, and output the shortest paths themselves.\n",
    "\n",
    "This problem is also called single-source shortest paths problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac16a10-f9cf-4938-ba78-481611bdaea6",
   "metadata": {},
   "source": [
    "## Algorithm¶\n",
    "Here is an algorithm described by the Dutch computer scientist Edsger W. Dijkstra in 1959.\n",
    "\n",
    "Let's create an array  \n",
    "$d[]$  where for each vertex  \n",
    "$v$  we store the current length of the shortest path from  \n",
    "$s$  to  \n",
    "$v$  in  \n",
    "$d[v]$ . Initially  \n",
    "$d[s] = 0$ , and for all other vertices this length equals infinity. In the implementation a sufficiently large number (which is guaranteed to be greater than any possible path length) is chosen as infinity.\n",
    "\n",
    " \n",
    "$$d[v] = \\infty,~ v \\ne s$$ \n",
    "In addition, we maintain a Boolean array  \n",
    "$u[]$  which stores for each vertex  \n",
    "$v$  whether it's marked. Initially all vertices are unmarked:\n",
    "\n",
    " \n",
    "$$u[v] = {\\rm false}$$ \n",
    "The Dijkstra's algorithm runs for  \n",
    "$n$  iterations. At each iteration a vertex  \n",
    "$v$  is chosen as unmarked vertex which has the least value  \n",
    "$d[v]$ :\n",
    "\n",
    "Evidently, in the first iteration the starting vertex  \n",
    "$s$  will be selected.\n",
    "\n",
    "The selected vertex  \n",
    "$v$  is marked. Next, from vertex  \n",
    "$v$  relaxations are performed: all edges of the form  \n",
    "$(v,\\text{to})$  are considered, and for each vertex  \n",
    "$\\text{to}$  the algorithm tries to improve the value  \n",
    "$d[\\text{to}]$ . If the length of the current edge equals  \n",
    "$len$ , the code for relaxation is:\n",
    "\n",
    " \n",
    "$$d[\\text{to}] = \\min (d[\\text{to}], d[v] + len)$$ \n",
    "After all such edges are considered, the current iteration ends. Finally, after  \n",
    "$n$  iterations, all vertices will be marked, and the algorithm terminates. We claim that the found values  \n",
    "$d[v]$  are the lengths of shortest paths from  \n",
    "$s$  to all vertices  \n",
    "$v$ .\n",
    "\n",
    "Note that if some vertices are unreachable from the starting vertex  \n",
    "$s$ , the values  \n",
    "$d[v]$  for them will remain infinite. Obviously, the last few iterations of the algorithm will choose those vertices, but no useful work will be done for them. Therefore, the algorithm can be stopped as soon as the selected vertex has infinite distance to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44335f38-dc25-42be-93af-d8f208911f5b",
   "metadata": {},
   "source": [
    "## Restoring Shortest Paths¶\n",
    "Usually one needs to know not only the lengths of shortest paths but also the shortest paths themselves. Let's see how to maintain sufficient information to restore the shortest path from  \n",
    "$s$  to any vertex. We'll maintain an array of predecessors  \n",
    "$p[]$  in which for each vertex  \n",
    "$v \\ne s$ ,  \n",
    "$p[v]$  is the penultimate vertex in the shortest path from  \n",
    "$s$  to  \n",
    "$v$ . Here we use the fact that if we take the shortest path to some vertex  \n",
    "$v$  and remove  \n",
    "$v$  from this path, we'll get a path ending in at vertex  \n",
    "$p[v]$ , and this path will be the shortest for the vertex  \n",
    "$p[v]$ . This array of predecessors can be used to restore the shortest path to any vertex: starting with  \n",
    "$v$ , repeatedly take the predecessor of the current vertex until we reach the starting vertex  \n",
    "$s$  to get the required shortest path with vertices listed in reverse order. So, the shortest path  \n",
    "$P$  to the vertex  \n",
    "$v$  is equal to:\n",
    "\n",
    " \n",
    "$$P = (s, \\ldots, p[p[p[v]]], p[p[v]], p[v], v)$$ \n",
    "Building this array of predecessors is very simple: for each successful relaxation, i.e. when for some selected vertex  \n",
    "$v$ , there is an improvement in the distance to some vertex  \n",
    "$\\text{to}$ , we update the predecessor vertex for  \n",
    "$\\text{to}$  with vertex  \n",
    "$v$ :\n",
    "\n",
    " \n",
    "$$p[\\text{to}] = v$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbfa172-4169-4c24-a6ff-0d22870d90ea",
   "metadata": {},
   "source": [
    "## Proof¶\n",
    "The main assertion on which Dijkstra's algorithm correctness is based is the following:\n",
    "\n",
    "After any vertex  \n",
    "$v$  becomes marked, the current distance to it  \n",
    "$d[v]$  is the shortest, and will no longer change.\n",
    "\n",
    "The proof is done by induction. For the first iteration this statement is obvious: the only marked vertex is  \n",
    "$s$ , and the distance to is  \n",
    "$d[s] = 0$  is indeed the length of the shortest path to  \n",
    "$s$ . Now suppose this statement is true for all previous iterations, i.e. for all already marked vertices; let's prove that it is not violated after the current iteration completes. Let  \n",
    "$v$  be the vertex selected in the current iteration, i.e.  \n",
    "$v$  is the vertex that the algorithm will mark. Now we have to prove that  \n",
    "$d[v]$  is indeed equal to the length of the shortest path to it  \n",
    "$l[v]$ .\n",
    "\n",
    "Consider the shortest path  \n",
    "$P$  to the vertex  \n",
    "$v$ . This path can be split into two parts:  \n",
    "$P_1$  which consists of only marked nodes (at least the starting vertex  \n",
    "$s$  is part of  \n",
    "$P_1$ ), and the rest of the path  \n",
    "$P_2$  (it may include a marked vertex, but it always starts with an unmarked vertex). Let's denote the first vertex of the path  \n",
    "$P_2$  as  \n",
    "$p$ , and the last vertex of the path  \n",
    "$P_1$  as  \n",
    "$q$ .\n",
    "\n",
    "First we prove our statement for the vertex  \n",
    "$p$ , i.e. let's prove that  \n",
    "$d[p] = l[p]$ . This is almost obvious: on one of the previous iterations we chose the vertex  \n",
    "$q$  and performed relaxation from it. Since (by virtue of the choice of vertex  \n",
    "$p$ ) the shortest path to  \n",
    "$p$  is the shortest path to  \n",
    "$q$  plus edge  \n",
    "$(p,q)$ , the relaxation from  \n",
    "$q$  set the value of  \n",
    "$d[p]$  to the length of the shortest path  \n",
    "$l[p]$ .\n",
    "\n",
    "Since the edges' weights are non-negative, the length of the shortest path  \n",
    "$l[p]$  (which we just proved to be equal to  \n",
    "$d[p]$ ) does not exceed the length  \n",
    "$l[v]$  of the shortest path to the vertex  \n",
    "$v$ . Given that  \n",
    "$l[v] \\le d[v]$  (because Dijkstra's algorithm could not have found a shorter way than the shortest possible one), we get the inequality:\n",
    "\n",
    " \n",
    "$$d[p] = l[p] \\le l[v] \\le d[v]$$ \n",
    "On the other hand, since both vertices  \n",
    "$p$  and  \n",
    "$v$  are unmarked, and the current iteration chose vertex  \n",
    "$v$ , not  \n",
    "$p$ , we get another inequality:\n",
    "\n",
    " \n",
    "$$d[p] \\ge d[v]$$ \n",
    "From these two inequalities we conclude that  \n",
    "$d[p] = d[v]$ , and then from previously found equations we get:\n",
    "\n",
    " \n",
    "$$d[v] = l[v]$$ \n",
    "Q.E.D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0bf046-4530-4112-88b6-c89ca8875a3b",
   "metadata": {},
   "source": [
    "## Implementation¶\n",
    "Dijkstra's algorithm performs  \n",
    "$n$  iterations. On each iteration it selects an unmarked vertex  \n",
    "$v$  with the lowest value  \n",
    "$d[v]$ , marks it and checks all the edges  \n",
    "$(v, \\text{to})$  attempting to improve the value  \n",
    "$d[\\text{to}]$ .\n",
    "\n",
    "The running time of the algorithm consists of:\n",
    "\n",
    " \n",
    "$n$  searches for a vertex with the smallest value  \n",
    "$d[v]$  among  \n",
    "$O(n)$  unmarked vertices\n",
    " \n",
    "$m$  relaxation attempts\n",
    "For the simplest implementation of these operations on each iteration vertex search requires  \n",
    "$O(n)$  operations, and each relaxation can be performed in  \n",
    "$O(1)$ . Hence, the resulting asymptotic behavior of the algorithm is:\n",
    "\n",
    " \n",
    "$$O(n^2+m)$$ \n",
    "This complexity is optimal for dense graph, i.e. when  \n",
    "$m \\approx n^2$ . However in sparse graphs, when  \n",
    "$m$  is much smaller than the maximal number of edges  \n",
    "$n^2$ , the problem can be solved in  \n",
    "$O(n \\log n + m)$  complexity. The algorithm and implementation can be found on the article Dijkstra on sparse graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd15993-03a7-4de8-bf61-0e4a79e14262",
   "metadata": {},
   "outputs": [],
   "source": [
    "const int INF = 1000000000;\n",
    "vector<vector<pair<int, int>>> adj;\n",
    "\n",
    "void dijkstra(int s, vector<int> & d, vector<int> & p) {\n",
    "    int n = adj.size();\n",
    "    d.assign(n, INF);\n",
    "    p.assign(n, -1);\n",
    "    vector<bool> u(n, false);\n",
    "\n",
    "    d[s] = 0;\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        int v = -1;\n",
    "        for (int j = 0; j < n; j++) {\n",
    "            if (!u[j] && (v == -1 || d[j] < d[v]))\n",
    "                v = j;\n",
    "        }\n",
    "\n",
    "        if (d[v] == INF)\n",
    "            break;\n",
    "\n",
    "        u[v] = true;\n",
    "        for (auto edge : adj[v]) {\n",
    "            int to = edge.first;\n",
    "            int len = edge.second;\n",
    "\n",
    "            if (d[v] + len < d[to]) {\n",
    "                d[to] = d[v] + len;\n",
    "                p[to] = v;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9931a-8db9-4d64-baba-98134487175e",
   "metadata": {},
   "source": [
    "Here the graph  \n",
    "$\\text{adj}$  is stored as adjacency list: for each vertex  \n",
    "$v$   \n",
    "$\\text{adj}[v]$  contains the list of edges going from this vertex, i.e. the list of pair<int,int> where the first element in the pair is the vertex at the other end of the edge, and the second element is the edge weight.\n",
    "\n",
    "The function takes the starting vertex  \n",
    "$s$  and two vectors that will be used as return values.\n",
    "\n",
    "First of all, the code initializes arrays: distances  \n",
    "$d[]$ , labels  \n",
    "$u[]$  and predecessors  \n",
    "$p[]$ . Then it performs  \n",
    "$n$  iterations. At each iteration the vertex  \n",
    "$v$  is selected which has the smallest distance  \n",
    "$d[v]$  among all the unmarked vertices. If the distance to selected vertex  \n",
    "$v$  is equal to infinity, the algorithm stops. Otherwise the vertex is marked, and all the edges going out from this vertex are checked. If relaxation along the edge is possible (i.e. distance  \n",
    "$d[\\text{to}]$  can be improved), the distance  \n",
    "$d[\\text{to}]$  and predecessor  \n",
    "$p[\\text{to}]$  are updated.\n",
    "\n",
    "After performing all the iterations array  \n",
    "$d[]$  stores the lengths of the shortest paths to all vertices, and array  \n",
    "$p[]$  stores the predecessors of all vertices (except starting vertex  \n",
    "$s$ ). The path to any vertex  \n",
    "$t$  can be restored in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778129f-0d46-41ae-9579-2e3c45177d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector<int> restore_path(int s, int t, vector<int> const& p) {\n",
    "    vector<int> path;\n",
    "\n",
    "    for (int v = t; v != s; v = p[v])\n",
    "        path.push_back(v);\n",
    "    path.push_back(s);\n",
    "\n",
    "    reverse(path.begin(), path.end());\n",
    "    return path;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c36614c-6b6b-4344-b618-21b74977bc86",
   "metadata": {},
   "source": [
    "# Dijkstra on sparse graphs\n",
    "\n",
    "For the statement of the problem, the algorithm with implementation and proof can be found on the article Dijkstra's algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1e774d-e713-44ad-b591-d83e2abe316c",
   "metadata": {},
   "source": [
    "## Algorithm¶\n",
    "We recall in the derivation of the complexity of Dijkstra's algorithm we used two factors: the time of finding the unmarked vertex with the smallest distance  \n",
    "$d[v]$ , and the time of the relaxation, i.e. the time of changing the values  \n",
    "$d[\\text{to}]$ .\n",
    "\n",
    "In the simplest implementation these operations require  \n",
    "$O(n)$  and  \n",
    "$O(1)$  time. Therefore, since we perform the first operation  \n",
    "$O(n)$  times, and the second one  \n",
    "$O(m)$  times, we obtained the complexity  \n",
    "$O(n^2 + m)$ .\n",
    "\n",
    "It is clear, that this complexity is optimal for a dense graph, i.e. when  \n",
    "$m \\approx n^2$ . However in sparse graphs, when  \n",
    "$m$  is much smaller than the maximal number of edges  \n",
    "$n^2$ , the complexity gets less optimal because of the first term. Thus it is necessary to improve the execution time of the first operation (and of course without greatly affecting the second operation by much).\n",
    "\n",
    "To accomplish that we can use a variation of multiple auxiliary data structures. The most efficient is the Fibonacci heap, which allows the first operation to run in  \n",
    "$O(\\log n)$ , and the second operation in  \n",
    "$O(1)$ . Therefore we will get the complexity  \n",
    "$O(n \\log n + m)$  for Dijkstra's algorithm, which is also the theoretical minimum for the shortest path search problem. Therefore this algorithm works optimal, and Fibonacci heaps are the optimal data structure. There doesn't exist any data structure, that can perform both operations in  \n",
    "$O(1)$ , because this would also allow to sort a list of random numbers in linear time, which is impossible. Interestingly there exists an algorithm by Thorup that finds the shortest path in  \n",
    "$O(m)$  time, however only works for integer weights, and uses a completely different idea. So this doesn't lead to any contradictions. Fibonacci heaps provide the optimal complexity for this task. However they are quite complex to implement, and also have a quite large hidden constant.\n",
    "\n",
    "As a compromise you can use data structures, that perform both types of operations (extracting a minimum and updating an item) in  \n",
    "$O(\\log n)$ . Then the complexity of Dijkstra's algorithm is  \n",
    "$O(n \\log n + m \\log n) = O(m \\log n)$ .\n",
    "\n",
    "C++ provides two such data structures: set and priority_queue. The first is based on red-black trees, and the second one on heaps. Therefore priority_queue has a smaller hidden constant, but also has a drawback: it doesn't support the operation of removing an element. Because of this we need to do a \"workaround\", that actually leads to a slightly worse factor  \n",
    "$\\log m$  instead of  \n",
    "$\\log n$  (although in terms of complexity they are identical)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577b80fb-11e1-4cd0-86b6-45a88a17b5e1",
   "metadata": {},
   "source": [
    "## Implementation¶\n",
    "### set¶\n",
    "Let us start with the container set. Since we need to store vertices ordered by their values  \n",
    "$d[]$ , it is convenient to store actual pairs: the distance and the index of the vertex. As a result in a set pairs are automatically sorted by their distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc2a4c-8e15-47a5-9887-9f4f363228a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "const int INF = 1000000000;\n",
    "vector<vector<pair<int, int>>> adj;\n",
    "\n",
    "void dijkstra(int s, vector<int> & d, vector<int> & p) {\n",
    "    int n = adj.size();\n",
    "    d.assign(n, INF);\n",
    "    p.assign(n, -1);\n",
    "\n",
    "    d[s] = 0;\n",
    "    set<pair<int, int>> q;\n",
    "    q.insert({0, s});\n",
    "    while (!q.empty()) {\n",
    "        int v = q.begin()->second;\n",
    "        q.erase(q.begin());\n",
    "\n",
    "        for (auto edge : adj[v]) {\n",
    "            int to = edge.first;\n",
    "            int len = edge.second;\n",
    "\n",
    "            if (d[v] + len < d[to]) {\n",
    "                q.erase({d[to], to});\n",
    "                d[to] = d[v] + len;\n",
    "                p[to] = v;\n",
    "                q.insert({d[to], to});\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da276a-8eec-4386-be92-eac998d1b0fb",
   "metadata": {},
   "source": [
    "We don't need the array  \n",
    "$u[]$  from the normal Dijkstra's algorithm implementation any more. We will use the set to store that information, and also find the vertex with the shortest distance with it. It kinda acts like a queue. The main loops executes until there are no more vertices in the set/queue. A vertex with the smallest distance gets extracted, and for each successful relaxation we first remove the old pair, and then after the relaxation add the new pair into the queue.\n",
    "\n",
    "## priority_queue¶\n",
    "The main difference to the implementation with set is that in many languages, including C++, we cannot remove elements from the priority_queue (although heaps can support that operation in theory). Therefore we have to use a workaround: We simply don't delete the old pair from the queue. As a result a vertex can appear multiple times with different distance in the queue at the same time. Among these pairs we are only interested in the pairs where the first element is equal to the corresponding value in  \n",
    "$d[]$ , all the other pairs are old. Therefore we need to make a small modification: at the beginning of each iteration, after extracting the next pair, we check if it is an important pair or if it is already an old and handled pair. This check is important, otherwise the complexity can increase up to  \n",
    "$O(n m)$ .\n",
    "\n",
    "By default a priority_queue sorts elements in descending order. To make it sort the elements in ascending order, we can either store the negated distances in it, or pass it a different sorting function. We will do the second option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e72714-060b-4f9a-82c5-c53a3d8130ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "const int INF = 1000000000;\n",
    "vector<vector<pair<int, int>>> adj;\n",
    "\n",
    "void dijkstra(int s, vector<int> & d, vector<int> & p) {\n",
    "    int n = adj.size();\n",
    "    d.assign(n, INF);\n",
    "    p.assign(n, -1);\n",
    "\n",
    "    d[s] = 0;\n",
    "    using pii = pair<int, int>;\n",
    "    priority_queue<pii, vector<pii>, greater<pii>> q;\n",
    "    q.push({0, s});\n",
    "    while (!q.empty()) {\n",
    "        int v = q.top().second;\n",
    "        int d_v = q.top().first;\n",
    "        q.pop();\n",
    "        if (d_v != d[v])\n",
    "            continue;\n",
    "\n",
    "        for (auto edge : adj[v]) {\n",
    "            int to = edge.first;\n",
    "            int len = edge.second;\n",
    "\n",
    "            if (d[v] + len < d[to]) {\n",
    "                d[to] = d[v] + len;\n",
    "                p[to] = v;\n",
    "                q.push({d[to], to});\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c459b7-1c7b-4734-ae98-2fa24b91c388",
   "metadata": {},
   "source": [
    "In practice the priority_queue version is a little bit faster than the version with set.\n",
    "\n",
    "Interestingly, a 2007 technical report concluded the variant of the algorithm not using decrease-key operations ran faster than the decrease-key variant, with a greater performance gap for sparse graphs.\n",
    "\n",
    "Getting rid of pairs¶\n",
    "You can improve the performance a little bit more if you don't store pairs in the containers, but only the vertex indices. In this case we must overload the comparison operator: it must compare two vertices using the distances stored in  \n",
    "$d[]$ .\n",
    "\n",
    "As a result of the relaxation, the distance of some vertices will change. However the data structure will not resort itself automatically. In fact changing distances of vertices in the queue, might destroy the data structure. As before, we need to remove the vertex before we relax it, and then insert it again afterwards.\n",
    "\n",
    "Since we only can remove from set, this optimization is only applicable for the set method, and doesn't work with priority_queue implementation. In practice this significantly increases the performance, especially when larger data types are used to store distances, like long long or double."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c660e2e-7a6c-46cb-b53b-333d454e8ef3",
   "metadata": {},
   "source": [
    "# Bellman-Ford Algorithm¶\r\n",
    "Single source shortest path with negative weight edges\r\n",
    "\r\n",
    "Suppose that we are given a weighted directed graph  \r\n",
    "$G$  with  \r\n",
    "$n$  vertices and  \r\n",
    "$m$  edges, and some specified vertex  \r\n",
    "$v$ . You want to find the length of shortest paths from vertex  \r\n",
    "$v$  to every other vertex.\r\n",
    "\r\n",
    "Unlike the Dijkstra algorithm, this algorithm can also be applied to graphs containing negative weight edges . However, if the graph contains a negative cycle, then, clearly, the shortest path to some vertices may not exist (due to the fact that the weight of the shortest path must be equal to minus infinity); however, this algorithm can be modified to signal the presence of a cycle of negative weight, or even deduce this cycle.\r\n",
    "\r\n",
    "The algorithm bears the name of two American scientists: Richard Bellman and Lester Ford. Ford actually invented this algorithm in 1956 during the study of another mathematical problem, which eventually reduced to a subproblem of finding the shortest paths in the graph, and Ford gave an outline of the algorithm to solve this problem. Bellman in 1958 published an article devoted specifically to the problem of finding the shortest path, and in this article he clearly formulated the algorithm in the form in which it is known hat it is greater than all possible path lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110dc451-0cfe-4523-9d44-20a68d8eea00",
   "metadata": {},
   "source": [
    "## Description of the algorithm¶\n",
    "Let us assume that the graph contains no negative weight cycle. The case of presence of a negative weight cycle will be discussed below in a separate section.\n",
    "\n",
    "We will create an array of distances  \n",
    "$d[0 \\ldots n-1]$ , which after execution of the algorithm will contain the answer to the problem. In the beginning we fill it as follows:  \n",
    "$d[v] = 0$ , and all other elements  \n",
    "$d[ ]$  equal to infinity  \n",
    "$\\infty$ .\n",
    "\n",
    "The algorithm consists of several phases. Each phase scans through all edges of the graph, and the algorithm tries to produce relaxation along each edge  \n",
    "$(a,b)$  having weight  \n",
    "$c$ . Relaxation along the edges is an attempt to improve the value  \n",
    "$d[b]$  using value  \n",
    "$d[a] + c$ . In fact, it means that we are trying to improve the answer for this vertex using edge  \n",
    "$(a,b)$  and current answer for vertex  \n",
    "$a$ .\n",
    "\n",
    "It is claimed that  \n",
    "$n-1$  phases of the algorithm are sufficient to correctly calculate the lengths of all shortest paths in the graph (again, we believe that the cycles of negative weight do not exist). For unreachable vertices the distance  \n",
    "$d[ ]$  will remain equal to infinity  \n",
    "$\\infty$ .\n",
    "\n",
    "## Implementation¶\n",
    "Unlike many other graph algorithms, for Bellman-Ford algorithm, it is more convenient to represent the graph using a single list of all edges (instead of  \n",
    "$n$  lists of edges - edges from each vertex). We start the implementation with a structure  \n",
    "$\\rm edge$  for representing the edges. The input to the algorithm are numbers  \n",
    "$n$ ,  \n",
    "$m$ , list  \n",
    "$e$  of edges and the starting vertex  \n",
    "$v$ . All the vertices are numbered  \n",
    "$0$  to  \n",
    "$n - 1$ .\n",
    "\n",
    "The simplest implementation¶\n",
    "The constant  \n",
    "$\\rm INF$  denotes the number \"infinity\" — it should be selected in such a way that it is greater than all possible path lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ca8f01-856e-4074-92dd-00df3dc72941",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Edge {\n",
    "    int a, b, cost;\n",
    "};\n",
    "\n",
    "int n, m, v;\n",
    "vector<Edge> edges;\n",
    "const int INF = 1000000000;\n",
    "\n",
    "void solve()\n",
    "{\n",
    "    vector<int> d(n, INF);\n",
    "    d[v] = 0;\n",
    "    for (int i = 0; i < n - 1; ++i)\n",
    "        for (Edge e : edges)\n",
    "            if (d[e.a] < INF)\n",
    "                d[e.b] = min(d[e.b], d[e.a] + e.cost);\n",
    "    // display d, for example, on the screen\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0047644-6068-45a1-b05e-6840d464bd7d",
   "metadata": {},
   "source": [
    "The check if (d[e.a] < INF) is needed only if the graph contains negative weight edges: no such verification would result in relaxation from the vertices to which paths have not yet found, and incorrect distance, of the type  \n",
    "$\\infty - 1$ ,  \n",
    "$\\infty - 2$  etc. would appear.\n",
    "\n",
    "## A better implementation¶\n",
    "This algorithm can be somewhat speeded up: often we already get the answer in a few phases and no useful work is done in remaining phases, just a waste visiting all edges. So, let's keep the flag, to tell whether something changed in the current phase or not, and if any phase, nothing changed, the algorithm can be stopped. (This optimization does not improve the asymptotic behavior, i.e., some graphs will still need all  \n",
    "$n-1$  phases, but significantly accelerates the behavior of the algorithm \"on an average\", i.e., on random graphs.)\n",
    "\n",
    "With this optimization, it is generally unnecessary to restrict manually the number of phases of the algorithm to  \n",
    "$n-1$  — the algorithm will stop after the desired number of phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee72f5-bf9b-4f99-a0f6-9b6110a46d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "void solve()\n",
    "{\n",
    "    vector<int> d(n, INF);\n",
    "    d[v] = 0;\n",
    "    for (;;) {\n",
    "        bool any = false;\n",
    "\n",
    "        for (Edge e : edges)\n",
    "            if (d[e.a] < INF)\n",
    "                if (d[e.b] > d[e.a] + e.cost) {\n",
    "                    d[e.b] = d[e.a] + e.cost;\n",
    "                    any = true;\n",
    "                }\n",
    "\n",
    "        if (!any)\n",
    "            break;\n",
    "    }\n",
    "    // display d, for example, on the screen\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5c0c65-fbc4-4a01-a5f1-4f7f798f6c64",
   "metadata": {},
   "source": [
    "## Retrieving Path¶\n",
    "Let us now consider how to modify the algorithm so that it not only finds the length of shortest paths, but also allows to reconstruct the shortest paths.\n",
    "\n",
    "For that, let's create another array  \n",
    "$p[0 \\ldots n-1]$ , where for each vertex we store its \"predecessor\", i.e. the penultimate vertex in the shortest path leading to it. In fact, the shortest path to any vertex  \n",
    "$a$  is a shortest path to some vertex  \n",
    "$p[a]$ , to which we added  \n",
    "$a$  at the end of the path.\n",
    "\n",
    "Note that the algorithm works on the same logic: it assumes that the shortest distance to one vertex is already calculated, and, tries to improve the shortest distance to other vertices from that vertex. Therefore, at the time of improvement we just need to remember  \n",
    "$p[ ]$ , i.e, the vertex from which this improvement has occurred.\n",
    "\n",
    "Following is an implementation of the Bellman-Ford with the retrieval of shortest path to a given node  \n",
    "$t$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f36f0-385b-4ed5-ae8e-1c53d7fefdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "void solve()\n",
    "{\n",
    "    vector<int> d(n, INF);\n",
    "    d[v] = 0;\n",
    "    vector<int> p(n, -1);\n",
    "\n",
    "    for (;;) {\n",
    "        bool any = false;\n",
    "        for (Edge e : edges)\n",
    "            if (d[e.a] < INF)\n",
    "                if (d[e.b] > d[e.a] + e.cost) {\n",
    "                    d[e.b] = d[e.a] + e.cost;\n",
    "                    p[e.b] = e.a;\n",
    "                    any = true;\n",
    "                }\n",
    "        if (!any)\n",
    "            break;\n",
    "    }\n",
    "\n",
    "    if (d[t] == INF)\n",
    "        cout << \"No path from \" << v << \" to \" << t << \".\";\n",
    "    else {\n",
    "        vector<int> path;\n",
    "        for (int cur = t; cur != -1; cur = p[cur])\n",
    "            path.push_back(cur);\n",
    "        reverse(path.begin(), path.end());\n",
    "\n",
    "        cout << \"Path from \" << v << \" to \" << t << \": \";\n",
    "        for (int u : path)\n",
    "            cout << u << ' ';\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb48553f-ef54-4b24-98e7-c8860fd68538",
   "metadata": {},
   "source": [
    "Here starting from the vertex  \n",
    "$t$ , we go through the predecessors till we reach starting vertex with no predecessor, and store all the vertices in the path in the list  \n",
    "$\\rm path$ . This list is a shortest path from  \n",
    "$v$  to  \n",
    "$t$ , but in reverse order, so we call  \n",
    "$\\rm reverse()$  function over  \n",
    "$\\rm path$  and then output the path.\n",
    "\n",
    "## The proof of the algorithm¶\n",
    "First, note that for all unreachable vertices  \n",
    "$u$  the algorithm will work correctly, the label  \n",
    "$d[u]$  will remain equal to infinity (because the algorithm Bellman-Ford will find some way to all reachable vertices from the start vertex  \n",
    "$v$ , and relaxation for all other remaining vertices will never happen).\n",
    "\n",
    "Let us now prove the following assertion: After the execution of  \n",
    "$i_{th}$  phase, the Bellman-Ford algorithm correctly finds all shortest paths whose number of edges does not exceed  \n",
    "$i$ .\n",
    "\n",
    "In other words, for any vertex  \n",
    "$a$  let us denote the  \n",
    "$k$  number of edges in the shortest path to it (if there are several such paths, you can take any). According to this statement, the algorithm guarantees that after  \n",
    "$k_{th}$  phase the shortest path for vertex  \n",
    "$a$  will be found.\n",
    "\n",
    "Proof: Consider an arbitrary vertex  \n",
    "$a$  to which there is a path from the starting vertex  \n",
    "$v$ , and consider a shortest path to it  \n",
    "$(p_0=v, p_1, \\ldots, p_k=a)$ . Before the first phase, the shortest path to the vertex  \n",
    "$p_0 = v$  was found correctly. During the first phase, the edge  \n",
    "$(p_0,p_1)$  has been checked by the algorithm, and therefore, the distance to the vertex  \n",
    "$p_1$  was correctly calculated after the first phase. Repeating this statement  \n",
    "$k$  times, we see that after  \n",
    "$k_{th}$  phase the distance to the vertex  \n",
    "$p_k = a$  gets calculated correctly, which we wanted to prove.\n",
    "\n",
    "The last thing to notice is that any shortest path cannot have more than  \n",
    "$n - 1$  edges. Therefore, the algorithm sufficiently goes up to the  \n",
    "$(n-1)_{th}$  phase. After that, it is guaranteed that no relaxation will improve the distance to some vertex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8189e3-c719-4b27-8ba8-ed93e9f3f81c",
   "metadata": {},
   "source": [
    "## The case of a negative cycle¶\n",
    "Everywhere above we considered that there is no negative cycle in the graph (precisely, we are interested in a negative cycle that is reachable from the starting vertex  \n",
    "$v$ , and, for an unreachable cycles nothing in the above algorithm changes). In the presence of a negative cycle(s), there are further complications associated with the fact that distances to all vertices in this cycle, as well as the distances to the vertices reachable from this cycle is not defined — they should be equal to minus infinity  \n",
    "$(- \\infty)$ .\n",
    "\n",
    "It is easy to see that the Bellman-Ford algorithm can endlessly do the relaxation among all vertices of this cycle and the vertices reachable from it. Therefore, if you do not limit the number of phases to  \n",
    "$n - 1$ , the algorithm will run indefinitely, constantly improving the distance from these vertices.\n",
    "\n",
    "Hence we obtain the criterion for presence of a cycle of negative weights reachable for source vertex  \n",
    "$v$ : after  \n",
    "$(n-1)_{th}$  phase, if we run algorithm for one more phase, and it performs at least one more relaxation, then the graph contains a negative weight cycle that is reachable from  \n",
    "$v$ ; otherwise, such a cycle does not exist.\n",
    "\n",
    "Moreover, if such a cycle is found, the Bellman-Ford algorithm can be modified so that it retrieves this cycle as a sequence of vertices contained in it. For this, it is sufficient to remember the last vertex  \n",
    "$x$  for which there was a relaxation in  \n",
    "$n_{th}$  phase. This vertex will either lie in a negative weight cycle, or is reachable from it. To get the vertices that are guaranteed to lie in a negative cycle, starting from the vertex  \n",
    "$x$ , pass through to the predecessors  \n",
    "$n$  times. Hence we will get the vertex  \n",
    "$y$ , namely the vertex in the cycle earliest reachable from source. We have to go from this vertex, through the predecessors, until we get back to the same vertex  \n",
    "$y$  (and it will happen, because relaxation in a negative weight cycle occur in a circular manner).\n",
    "\n",
    "## Implementation:¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b34f7a-34e1-4eaa-816f-fc35f0d988d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "void solve()\n",
    "{\n",
    "    vector<int> d(n, INF);\n",
    "    d[v] = 0;\n",
    "    vector<int> p(n, -1);\n",
    "    int x;\n",
    "    for (int i = 0; i < n; ++i) {\n",
    "        x = -1;\n",
    "        for (Edge e : edges)\n",
    "            if (d[e.a] < INF)\n",
    "                if (d[e.b] > d[e.a] + e.cost) {\n",
    "                    d[e.b] = max(-INF, d[e.a] + e.cost);\n",
    "                    p[e.b] = e.a;\n",
    "                    x = e.b;\n",
    "                }\n",
    "    }\n",
    "\n",
    "    if (x == -1)\n",
    "        cout << \"No negative cycle from \" << v;\n",
    "    else {\n",
    "        int y = x;\n",
    "        for (int i = 0; i < n; ++i)\n",
    "            y = p[y];\n",
    "\n",
    "        vector<int> path;\n",
    "        for (int cur = y;; cur = p[cur]) {\n",
    "            path.push_back(cur);\n",
    "            if (cur == y && path.size() > 1)\n",
    "                break;\n",
    "        }\n",
    "        reverse(path.begin(), path.end());\n",
    "\n",
    "        cout << \"Negative cycle: \";\n",
    "        for (int u : path)\n",
    "            cout << u << ' ';\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bdb93b-6370-441d-a71a-37177c06f450",
   "metadata": {},
   "source": [
    "Due to the presence of a negative cycle, for  \n",
    "$n$  iterations of the algorithm, the distances may go far in the negative range (to negative numbers of the order of  \n",
    "$-n m W$ , where  \n",
    "$W$  is the maximum absolute value of any weight in the graph). Hence in the code, we adopted additional measures against the integer overflow as follows:\n",
    "\n",
    "d[e.b] = max(-INF, d[e.a] + e.cost);\n",
    "The above implementation looks for a negative cycle reachable from some starting vertex  \n",
    "$v$ ; however, the algorithm can be modified to just looking for any negative cycle in the graph. For this we need to put all the distance  \n",
    "$d[i]$  to zero and not infinity — as if we are looking for the shortest path from all vertices simultaneously; the validity of the detection of a negative cycle is not affected.\n",
    "\n",
    "For more on this topic — see separate article, Finding a negative cycle in the graph.\n",
    "\n",
    "## Shortest Path Faster Algorithm (SPFA)¶\n",
    "SPFA is a improvement of the Bellman-Ford algorithm which takes advantage of the fact that not all attempts at relaxation will work. The main idea is to create a queue containing only the vertices that were relaxed but that still could further relax their neighbors. And whenever you can relax some neighbor, you should put him in the queue. This algorithm can also be used to detect negative cycles as the Bellman-Ford.\n",
    "\n",
    "The worst case of this algorithm is equal to the  \n",
    "$O(n m)$  of the Bellman-Ford, but in practice it works much faster and some people claim that it works even in  \n",
    "$O(m)$  on average. However be careful, because this algorithm is deterministic and it is easy to create counterexamples that make the algorithm run in  \n",
    "$O(n m)$ .\n",
    "\n",
    "There are some care to be taken in the implementation, such as the fact that the algorithm continues forever if there is a negative cycle. To avoid this, it is possible to create a counter that stores how many times a vertex has been relaxed and stop the algorithm as soon as some vertex got relaxed for the  \n",
    "$n$ -th time. Note, also there is no reason to put a vertex in the queue if it is already in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dba5be-b9d5-44fc-88e0-0973f3f210de",
   "metadata": {},
   "outputs": [],
   "source": [
    "const int INF = 1000000000;\n",
    "vector<vector<pair<int, int>>> adj;\n",
    "\n",
    "bool spfa(int s, vector<int>& d) {\n",
    "    int n = adj.size();\n",
    "    d.assign(n, INF);\n",
    "    vector<int> cnt(n, 0);\n",
    "    vector<bool> inqueue(n, false);\n",
    "    queue<int> q;\n",
    "\n",
    "    d[s] = 0;\n",
    "    q.push(s);\n",
    "    inqueue[s] = true;\n",
    "    while (!q.empty()) {\n",
    "        int v = q.front();\n",
    "        q.pop();\n",
    "        inqueue[v] = false;\n",
    "\n",
    "        for (auto edge : adj[v]) {\n",
    "            int to = edge.first;\n",
    "            int len = edge.second;\n",
    "\n",
    "            if (d[v] + len < d[to]) {\n",
    "                d[to] = d[v] + len;\n",
    "                if (!inqueue[to]) {\n",
    "                    q.push(to);\n",
    "                    inqueue[to] = true;\n",
    "                    cnt[to]++;\n",
    "                    if (cnt[to] > n)\n",
    "                        return false;  // negative cycle\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return true;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ce267-bdeb-495b-83d3-3dd970f4d778",
   "metadata": {},
   "source": [
    "# Lowest Common Ancestor -  $O(\\sqrt{N})$  and  $O(\\log N)$  with  $O(N)$  preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d9c702-f2f8-41e3-a466-996607816e82",
   "metadata": {},
   "source": [
    "Given a tree  \n",
    "$G$ . Given queries of the form  \n",
    "$(v_1, v_2)$ , for each query you need to find the lowest common ancestor (or least common ancestor), i.e. a vertex  \n",
    "$v$  that lies on the path from the root to  \n",
    "$v_1$  and the path from the root to  \n",
    "$v_2$ , and the vertex should be the lowest. In other words, the desired vertex  \n",
    "$v$  is the most bottom ancestor of  \n",
    "$v_1$  and  \n",
    "$v_2$ . It is obvious that their lowest common ancestor lies on a shortest path from  \n",
    "$v_1$  and  \n",
    "$v_2$ . Also, if  \n",
    "$v_1$  is the ancestor of  \n",
    "$v_2$ ,  \n",
    "$v_1$  is their lowest common ancestor.\n",
    "\n",
    "## The Idea of the Algorithm¶\n",
    "Before answering the queries, we need to preprocess the tree. We make a DFS traversal starting at the root and we build a list  \n",
    "$\\text{euler}$  which stores the order of the vertices that we visit (a vertex is added to the list when we first visit it, and after the return of the DFS traversals to its children). This is also called an Euler tour of the tree. It is clear that the size of this list will be  \n",
    "$O(N)$ . We also need to build an array  \n",
    "$\\text{first}[0..N-1]$  which stores for each vertex  \n",
    "$i$  its first occurrence in  \n",
    "$\\text{euler}$ . That is, the first position in  \n",
    "$\\text{euler}$  such that  \n",
    "$\\text{euler}[\\text{first}[i]] = i$ . Also by using the DFS we can find the height of each node (distance from root to it) and store it in the array  \n",
    "$\\text{height}[0..N-1]$ .\n",
    "\n",
    "So how can we answer queries using the Euler tour and the additional two arrays? Suppose the query is a pair of  \n",
    "$v_1$  and  \n",
    "$v_2$ . Consider the vertices that we visit in the Euler tour between the first visit of  \n",
    "$v_1$  and the first visit of  \n",
    "$v_2$ . It is easy to see, that the  \n",
    "$\\text{LCA}(v_1, v_2)$  is the vertex with the lowest height on this path. We already noticed, that the LCA has to be part of the shortest path between  \n",
    "$v_1$  and  \n",
    "$v_2$ . Clearly it also has to be the vertex with the smallest height. And in the Euler tour we essentially use the shortest path, except that we additionally visit all subtrees that we find on the path. But all vertices in these subtrees are lower in the tree than the LCA and therefore have a larger height. So the  \n",
    "$\\text{LCA}(v_1, v_2)$  can be uniquely determined by finding the vertex with the smallest height in the Euler tour between  \n",
    "$\\text{first}(v_1)$  and  \n",
    "$\\text{first}(v_2)$ .\n",
    "\n",
    "Let's illustrate this idea. Consider the following graph and the Euler tour with the corresponding heights:\n",
    "\n",
    "LCA_Euler_Tour\n",
    "  \n",
    " \n",
    " \n",
    "$$\\begin{array}{|l|c|c|c|c|c|c|c|c|c|c|c|c|c|} \\hline \\text{Vertices:} & 1 & 2 & 5 & 2 & 6 & 2 & 1 & 3 & 1 & 4 & 7 & 4 & 1 \\\\ \\hline \\text{Heights:} & 1 & 2 & 3 & 2 & 3 & 2 & 1 & 2 & 1 & 2 & 3 & 2 & 1 \\\\ \\hline \\end{array}$$ \n",
    "The tour starting at vertex  \n",
    "$6$  and ending at  \n",
    "$4$  we visit the vertices  \n",
    "$[6, 2, 1, 3, 1, 4]$ . Among those vertices the vertex  \n",
    "$1$  has the lowest height, therefore  \n",
    "$\\text{LCA(6, 4) = 1}$ .\n",
    "\n",
    "To recap: to answer a query we just need to find the vertex with smallest height in the array  \n",
    "$\\text{euler}$  in the range from  \n",
    "$\\text{first}[v_1]$  to  \n",
    "$\\text{first}[v_2]$ . Thus, the LCA problem is reduced to the RMQ problem (finding the minimum in an range problem).\n",
    "\n",
    "Using Sqrt-Decomposition, it is possible to obtain a solution answering each query in  \n",
    "$O(\\sqrt{N})$  with preprocessing in  \n",
    "$O(N)$  time.\n",
    "\n",
    "Using a Segment Tree you can answer each query in  \n",
    "$O(\\log N)$  with preprocessing in  \n",
    "$O(N)$  time.\n",
    "\n",
    "Since there will almost never be any update to the stored values, a Sparse Table might be a better choice, allowing  \n",
    "$O(1)$  query answering with  \n",
    "$O(N\\log N)$  build time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be399337-cef2-44f9-9110-06cc557e55cd",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "In the following implementation of the LCA algorithm a Segment Tree is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3556ef-bb32-4928-9d26-1766b828105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct LCA {\n",
    "    vector<int> height, euler, first, segtree;\n",
    "    vector<bool> visited;\n",
    "    int n;\n",
    "\n",
    "    LCA(vector<vector<int>> &adj, int root = 0) {\n",
    "        n = adj.size();\n",
    "        height.resize(n);\n",
    "        first.resize(n);\n",
    "        euler.reserve(n * 2);\n",
    "        visited.assign(n, false);\n",
    "        dfs(adj, root);\n",
    "        int m = euler.size();\n",
    "        segtree.resize(m * 4);\n",
    "        build(1, 0, m - 1);\n",
    "    }\n",
    "\n",
    "    void dfs(vector<vector<int>> &adj, int node, int h = 0) {\n",
    "        visited[node] = true;\n",
    "        height[node] = h;\n",
    "        first[node] = euler.size();\n",
    "        euler.push_back(node);\n",
    "        for (auto to : adj[node]) {\n",
    "            if (!visited[to]) {\n",
    "                dfs(adj, to, h + 1);\n",
    "                euler.push_back(node);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    void build(int node, int b, int e) {\n",
    "        if (b == e) {\n",
    "            segtree[node] = euler[b];\n",
    "        } else {\n",
    "            int mid = (b + e) / 2;\n",
    "            build(node << 1, b, mid);\n",
    "            build(node << 1 | 1, mid + 1, e);\n",
    "            int l = segtree[node << 1], r = segtree[node << 1 | 1];\n",
    "            segtree[node] = (height[l] < height[r]) ? l : r;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    int query(int node, int b, int e, int L, int R) {\n",
    "        if (b > R || e < L)\n",
    "            return -1;\n",
    "        if (b >= L && e <= R)\n",
    "            return segtree[node];\n",
    "        int mid = (b + e) >> 1;\n",
    "\n",
    "        int left = query(node << 1, b, mid, L, R);\n",
    "        int right = query(node << 1 | 1, mid + 1, e, L, R);\n",
    "        if (left == -1) return right;\n",
    "        if (right == -1) return left;\n",
    "        return height[left] < height[right] ? left : right;\n",
    "    }\n",
    "\n",
    "    int lca(int u, int v) {\n",
    "        int left = first[u], right = first[v];\n",
    "        if (left > right)\n",
    "            swap(left, right);\n",
    "        return query(1, 0, euler.size() - 1, left, right);\n",
    "    }\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd59a2-b812-4ab9-b70b-4bc2c11e8d5a",
   "metadata": {},
   "source": [
    "# Lowest Common Ancestor - Binary Lifting\n",
    "\n",
    "Let  \n",
    "$G$  be a tree. For every query of the form (u, v) we want to find the lowest common ancestor of the nodes u and v, i.e. we want to find a node w that lies on the path from u to the root node, that lies on the path from v to the root node, and if there are multiple nodes we pick the one that is farthest away from the root node. In other words the desired node w is the lowest ancestor of u and v. In particular if u is an ancestor of v, then u is their lowest common ancestor.\n",
    "\n",
    "The algorithm described in this article will need  \n",
    "$O(N \\log N)$  for preprocessing the tree, and then  \n",
    "$O(\\log N)$  for each LCA query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1142483-7e4f-45fb-b572-35cb9b52d41e",
   "metadata": {},
   "source": [
    "## Algorithm¶\n",
    "For each node we will precompute its ancestor above him, its ancestor two nodes above, its ancestor four above, etc. Let's store them in the array up, i.e. up[i][j] is the 2^j-th ancestor above the node i with i=1...N, j=0...ceil(log(N)). These information allow us to jump from any node to any ancestor above it in  \n",
    "$O(\\log N)$  time. We can compute this array using a DFS traversal of the tree.\n",
    "\n",
    "For each node we will also remember the time of the first visit of this node (i.e. the time when the DFS discovers the node), and the time when we left it (i.e. after we visited all children and exit the DFS function). We can use this information to determine in constant time if a node is an ancestor of another node.\n",
    "\n",
    "Suppose now we received a query (u, v). We can immediately check whether one node is the ancestor of the other. In this case this node is already the LCA. If u is not the ancestor of v, and v not the ancestor of u, we climb the ancestors of u until we find the highest (i.e. closest to the root) node, which is not an ancestor of v (i.e. a node x, such that x is not an ancestor of v, but up[x][0] is). We can find this node x in  \n",
    "$O(\\log N)$  time using the array up.\n",
    "\n",
    "We will describe this process in more detail. Let L = ceil(log(N)). Suppose first that i = L. If up[u][i] is not an ancestor of v, then we can assign u = up[u][i] and decrement i. If up[u][i] is an ancestor, then we just decrement i. Clearly after doing this for all non-negative i the node u will be the desired node - i.e. u is still not an ancestor of v, but up[u][0] is.\n",
    "\n",
    "Now, obviously, the answer to LCA will be up[u][0] - i.e., the smallest node among the ancestors of the node u, which is also an ancestor of v.\n",
    "\n",
    "So answering a LCA query will iterate i from ceil(log(N)) to 0 and checks in each iteration if one node is the ancestor of the other. Consequently each query can be answered in  \n",
    "$O(\\log N)$ .\n",
    "\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5010a4d2-cb42-4ea1-b739-9c70472fdffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "int n, l;\n",
    "vector<vector<int>> adj;\n",
    "\n",
    "int timer;\n",
    "vector<int> tin, tout;\n",
    "vector<vector<int>> up;\n",
    "\n",
    "void dfs(int v, int p)\n",
    "{\n",
    "    tin[v] = ++timer;\n",
    "    up[v][0] = p;\n",
    "    for (int i = 1; i <= l; ++i)\n",
    "        up[v][i] = up[up[v][i-1]][i-1];\n",
    "\n",
    "    for (int u : adj[v]) {\n",
    "        if (u != p)\n",
    "            dfs(u, v);\n",
    "    }\n",
    "\n",
    "    tout[v] = ++timer;\n",
    "}\n",
    "\n",
    "bool is_ancestor(int u, int v)\n",
    "{\n",
    "    return tin[u] <= tin[v] && tout[u] >= tout[v];\n",
    "}\n",
    "\n",
    "int lca(int u, int v)\n",
    "{\n",
    "    if (is_ancestor(u, v))\n",
    "        return u;\n",
    "    if (is_ancestor(v, u))\n",
    "        return v;\n",
    "    for (int i = l; i >= 0; --i) {\n",
    "        if (!is_ancestor(up[u][i], v))\n",
    "            u = up[u][i];\n",
    "    }\n",
    "    return up[u][0];\n",
    "}\n",
    "\n",
    "void preprocess(int root) {\n",
    "    tin.resize(n);\n",
    "    tout.resize(n);\n",
    "    timer = 0;\n",
    "    l = ceil(log2(n));\n",
    "    up.assign(n, vector<int>(l + 1));\n",
    "    dfs(root, root);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720864ea-119a-4934-8a10-bb9f0a6ebbb5",
   "metadata": {},
   "source": [
    "# Lowest Common Ancestor - Farach-Colton and Bender Algorithm¶\n",
    "Let  \n",
    "$G$  be a tree. For every query of the form  \n",
    "$(u, v)$  we want to find the lowest common ancestor of the nodes  \n",
    "$u$  and  \n",
    "$v$ , i.e. we want to find a node  \n",
    "$w$  that lies on the path from  \n",
    "$u$  to the root node, that lies on the path from  \n",
    "$v$  to the root node, and if there are multiple nodes we pick the one that is farthest away from the root node. In other words the desired node  \n",
    "$w$  is the lowest ancestor of  \n",
    "$u$  and  \n",
    "$v$ . In particular if  \n",
    "$u$  is an ancestor of  \n",
    "$v$ , then  \n",
    "$u$  is their lowest common ancestor.\n",
    "\n",
    "The algorithm which will be described in this article was developed by Farach-Colton and Bender. It is asymptotically optimal.\n",
    "\n",
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5dd9b0-addf-4b3b-962f-d59af8ad116f",
   "metadata": {},
   "source": [
    "We use the classical reduction of the LCA problem to the RMQ problem. We traverse all nodes of the tree with DFS and keep an array with all visited nodes and the heights of these nodes. The LCA of two nodes  \n",
    "$u$  and  \n",
    "$v$  is the node between the occurrences of  \n",
    "$u$  and  \n",
    "$v$  in the tour, that has the smallest height.\n",
    "\n",
    "In the following picture you can see a possible Euler-Tour of a graph and in the list below you can see the visited nodes and their heights.\n",
    "\n",
    "LCA_Euler_Tour\n",
    "  \n",
    " \n",
    " \n",
    "$$\\begin{array}{|l|c|c|c|c|c|c|c|c|c|c|c|c|c|} \\hline \\text{Nodes:} & 1 & 2 & 5 & 2 & 6 & 2 & 1 & 3 & 1 & 4 & 7 & 4 & 1 \\\\ \\hline \\text{Heights:} & 1 & 2 & 3 & 2 & 3 & 2 & 1 & 2 & 1 & 2 & 3 & 2 & 1 \\\\ \\hline \\end{array}$$ \n",
    "You can read more about this reduction in the article Lowest Common Ancestor. In that article the minimum of a range was either found by sqrt-decomposition in  \n",
    "$O(\\sqrt{N})$  or in  \n",
    "$O(\\log N)$  using a Segment tree. In this article we look at how we can solve the given range minimum queries in  \n",
    "$O(1)$  time, while still only taking  \n",
    "$O(N)$  time for preprocessing.\n",
    "\n",
    "Note that the reduced RMQ problem is very specific: any two adjacent elements in the array differ exactly by one (since the elements of the array are nothing more than the heights of the nodes visited in order of traversal, and we either go to a descendant, in which case the next element is one bigger, or go back to the ancestor, in which case the next element is one lower). The Farach-Colton and Bender algorithm describes a solution for exactly this specialized RMQ problem.\n",
    "\n",
    "Let's denote with  \n",
    "$A$  the array on which we want to perform the range minimum queries. And  \n",
    "$N$  will be the size of  \n",
    "$A$ .\n",
    "\n",
    "There is an easy data structure that we can use for solving the RMQ problem with  \n",
    "$O(N \\log N)$  preprocessing and  \n",
    "$O(1)$  for each query: the Sparse Table. We create a table  \n",
    "$T$  where each element  \n",
    "$T[i][j]$  is equal to the minimum of  \n",
    "$A$  in the interval  \n",
    "$[i, i + 2^j - 1]$ . Obviously  \n",
    "$0 \\leq j \\leq \\lceil \\log N \\rceil$ , and therefore the size of the Sparse Table will be  \n",
    "$O(N \\log N)$ . You can build the table easily in  \n",
    "$O(N \\log N)$  by noting that  \n",
    "$T[i][j] = \\min(T[i][j-1], T[i+2^{j-1}][j-1])$ .\n",
    "\n",
    "How can we answer a query RMQ in  \n",
    "$O(1)$  using this data structure? Let the received query be  \n",
    "$[l, r]$ , then the answer is  \n",
    "$\\min(T[l][\\text{sz}], T[r-2^{\\text{sz}}+1][\\text{sz}])$ , where  \n",
    "$\\text{sz}$  is the biggest exponent such that  \n",
    "$2^{\\text{sz}}$  is not bigger than the range length  \n",
    "$r-l+1$ . Indeed we can take the range  \n",
    "$[l, r]$  and cover it two segments of length  \n",
    "$2^{\\text{sz}}$  - one starting in  \n",
    "$l$  and the other ending in  \n",
    "$r$ . These segments overlap, but this doesn't interfere with our computation. To really achieve the time complexity of  \n",
    "$O(1)$  per query, we need to know the values of  \n",
    "$\\text{sz}$  for all possible lengths from  \n",
    "$1$  to  \n",
    "$N$ . But this can be easily precomputed.\n",
    "\n",
    "Now we want to improve the complexity of the preprocessing down to  \n",
    "$O(N)$ .\n",
    "\n",
    "We divide the array  \n",
    "$A$  into blocks of size  \n",
    "$K = 0.5 \\log N$  with  \n",
    "$\\log$  being the logarithm to base 2. For each block we calculate the minimum element and store them in an array  \n",
    "$B$ .  \n",
    "$B$  has the size  \n",
    " \n",
    " \n",
    "$\\frac{N}{K}$ . We construct a sparse table from the array  \n",
    "$B$ . The size and the time complexity of it will be:\n",
    "\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "$$\\frac{N}{K}\\log\\left(\\frac{N}{K}\\right) = \\frac{2N}{\\log(N)} \\log\\left(\\frac{2N}{\\log(N)}\\right) =$$ \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "$$= \\frac{2N}{\\log(N)} \\left(1 + \\log\\left(\\frac{N}{\\log(N)}\\right)\\right) \\leq \\frac{2N}{\\log(N)} + 2N = O(N)$$ \n",
    "Now we only have to learn how to quickly answer range minimum queries within each block. In fact if the received range minimum query is  \n",
    "$[l, r]$  and  \n",
    "$l$  and  \n",
    "$r$  are in different blocks then the answer is the minimum of the following three values: the minimum of the suffix of block of  \n",
    "$l$  starting at  \n",
    "$l$ , the minimum of the prefix of block of  \n",
    "$r$  ending at  \n",
    "$r$ , and the minimum of the blocks between those. The minimum of the blocks in between can be answered in  \n",
    "$O(1)$  using the Sparse Table. So this leaves us only the range minimum queries inside blocks.\n",
    "\n",
    "Here we will exploit the property of the array. Remember that the values in the array - which are just height values in the tree - will always differ by one. If we remove the first element of a block, and subtract it from every other item in the block, every block can be identified by a sequence of length  \n",
    "$K - 1$  consisting of the number  \n",
    "$+1$  and  \n",
    "$-1$ . Because these blocks are so small, there are only a few different sequences that can occur. The number of possible sequences is:\n",
    "\n",
    " \n",
    "$$2^{K-1} = 2^{0.5 \\log(N) - 1} = 0.5 \\left(2^{\\log(N)}\\right)^{0.5} = 0.5 \\sqrt{N}$$ \n",
    "Thus the number of different blocks is  \n",
    "$O(\\sqrt{N})$ , and therefore we can precompute the results of range minimum queries inside all different blocks in  \n",
    "$O(\\sqrt{N} K^2) = O(\\sqrt{N} \\log^2(N)) = O(N)$  time. For the implementation we can characterize a block by a bitmask of length  \n",
    "$K-1$  (which will fit in a standard int) and store the index of the minimum in an array  \n",
    "$\\text{block}[\\text{mask}][l][r]$  of size  \n",
    "$O(\\sqrt{N} \\log^2(N))$ .\n",
    "\n",
    "So we learned how to precompute range minimum queries within each block, as well as range minimum queries over a range of blocks, all in  \n",
    "$O(N)$ . With these precomputations we can answer each query in  \n",
    "$O(1)$ , by using at most four precomputed values: the minimum of the block containing l, the minimum of the block containing r, and the two minima of the overlapping segments of the blocks between them.\n",
    "\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e0cf2-9ae6-4632-8e7f-8f082685c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "int n;\n",
    "vector<vector<int>> adj;\n",
    "\n",
    "int block_size, block_cnt;\n",
    "vector<int> first_visit;\n",
    "vector<int> euler_tour;\n",
    "vector<int> height;\n",
    "vector<int> log_2;\n",
    "vector<vector<int>> st;\n",
    "vector<vector<vector<int>>> blocks;\n",
    "vector<int> block_mask;\n",
    "\n",
    "void dfs(int v, int p, int h) {\n",
    "    first_visit[v] = euler_tour.size();\n",
    "    euler_tour.push_back(v);\n",
    "    height[v] = h;\n",
    "\n",
    "    for (int u : adj[v]) {\n",
    "        if (u == p)\n",
    "            continue;\n",
    "        dfs(u, v, h + 1);\n",
    "        euler_tour.push_back(v);\n",
    "    }\n",
    "}\n",
    "\n",
    "int min_by_h(int i, int j) {\n",
    "    return height[euler_tour[i]] < height[euler_tour[j]] ? i : j;\n",
    "}\n",
    "\n",
    "void precompute_lca(int root) {\n",
    "    // get euler tour & indices of first occurrences\n",
    "    first_visit.assign(n, -1);\n",
    "    height.assign(n, 0);\n",
    "    euler_tour.reserve(2 * n);\n",
    "    dfs(root, -1, 0);\n",
    "\n",
    "    // precompute all log values\n",
    "    int m = euler_tour.size();\n",
    "    log_2.reserve(m + 1);\n",
    "    log_2.push_back(-1);\n",
    "    for (int i = 1; i <= m; i++)\n",
    "        log_2.push_back(log_2[i / 2] + 1);\n",
    "\n",
    "    block_size = max(1, log_2[m] / 2);\n",
    "    block_cnt = (m + block_size - 1) / block_size;\n",
    "\n",
    "    // precompute minimum of each block and build sparse table\n",
    "    st.assign(block_cnt, vector<int>(log_2[block_cnt] + 1));\n",
    "    for (int i = 0, j = 0, b = 0; i < m; i++, j++) {\n",
    "        if (j == block_size)\n",
    "            j = 0, b++;\n",
    "        if (j == 0 || min_by_h(i, st[b][0]) == i)\n",
    "            st[b][0] = i;\n",
    "    }\n",
    "    for (int l = 1; l <= log_2[block_cnt]; l++) {\n",
    "        for (int i = 0; i < block_cnt; i++) {\n",
    "            int ni = i + (1 << (l - 1));\n",
    "            if (ni >= block_cnt)\n",
    "                st[i][l] = st[i][l-1];\n",
    "            else\n",
    "                st[i][l] = min_by_h(st[i][l-1], st[ni][l-1]);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // precompute mask for each block\n",
    "    block_mask.assign(block_cnt, 0);\n",
    "    for (int i = 0, j = 0, b = 0; i < m; i++, j++) {\n",
    "        if (j == block_size)\n",
    "            j = 0, b++;\n",
    "        if (j > 0 && (i >= m || min_by_h(i - 1, i) == i - 1))\n",
    "            block_mask[b] += 1 << (j - 1);\n",
    "    }\n",
    "\n",
    "    // precompute RMQ for each unique block\n",
    "    int possibilities = 1 << (block_size - 1);\n",
    "    blocks.resize(possibilities);\n",
    "    for (int b = 0; b < block_cnt; b++) {\n",
    "        int mask = block_mask[b];\n",
    "        if (!blocks[mask].empty())\n",
    "            continue;\n",
    "        blocks[mask].assign(block_size, vector<int>(block_size));\n",
    "        for (int l = 0; l < block_size; l++) {\n",
    "            blocks[mask][l][l] = l;\n",
    "            for (int r = l + 1; r < block_size; r++) {\n",
    "                blocks[mask][l][r] = blocks[mask][l][r - 1];\n",
    "                if (b * block_size + r < m)\n",
    "                    blocks[mask][l][r] = min_by_h(b * block_size + blocks[mask][l][r], \n",
    "                            b * block_size + r) - b * block_size;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int lca_in_block(int b, int l, int r) {\n",
    "    return blocks[block_mask[b]][l][r] + b * block_size;\n",
    "}\n",
    "\n",
    "int lca(int v, int u) {\n",
    "    int l = first_visit[v];\n",
    "    int r = first_visit[u];\n",
    "    if (l > r)\n",
    "        swap(l, r);\n",
    "    int bl = l / block_size;\n",
    "    int br = r / block_size;\n",
    "    if (bl == br)\n",
    "        return euler_tour[lca_in_block(bl, l % block_size, r % block_size)];\n",
    "    int ans1 = lca_in_block(bl, l % block_size, block_size - 1);\n",
    "    int ans2 = lca_in_block(br, 0, r % block_size);\n",
    "    int ans = min_by_h(ans1, ans2);\n",
    "    if (bl + 1 < br) {\n",
    "        int l = log_2[br - bl - 1];\n",
    "        int ans3 = st[bl+1][l];\n",
    "        int ans4 = st[br - (1 << l)][l];\n",
    "        ans = min_by_h(ans, min_by_h(ans3, ans4));\n",
    "    }\n",
    "    return euler_tour[ans];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a392ab-8e16-40d6-bf20-bd4fbabd8a27",
   "metadata": {},
   "source": [
    "# Number of paths of fixed length / Shortest paths of fixed length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038328f-db4c-48ae-ad31-3dfbd81bb4ec",
   "metadata": {},
   "source": [
    "The following article describes solutions to these two problems built on the same idea: reduce the problem to the construction of matrix and compute the solution with the usual matrix multiplication or with a modified multiplication.\n",
    "\n",
    "## Number of paths of a fixed length¶\n",
    "We are given a directed, unweighted graph  \n",
    "$G$  with  \n",
    "$n$  vertices and we are given an integer  \n",
    "$k$ . The task is the following: for each pair of vertices  \n",
    "$(i, j)$  we have to find the number of paths of length  \n",
    "$k$  between these vertices. Paths don't have to be simple, i.e. vertices and edges can be visited any number of times in a single path.\n",
    "\n",
    "We assume that the graph is specified with an adjacency matrix, i.e. the matrix  \n",
    "$G[][]$  of size  \n",
    "$n \\times n$ , where each element  \n",
    "$G[i][j]$  equal to  \n",
    "$1$  if the vertex  \n",
    "$i$  is connected with  \n",
    "$j$  by an edge, and  \n",
    "$0$  is they are not connected by an edge. The following algorithm works also in the case of multiple edges: if some pair of vertices  \n",
    "$(i, j)$  is connected with  \n",
    "$m$  edges, then we can record this in the adjacency matrix by setting  \n",
    "$G[i][j] = m$ . Also the algorithm works if the graph contains loops (a loop is an edge that connect a vertex with itself).\n",
    "\n",
    "It is obvious that the constructed adjacency matrix if the answer to the problem for the case  \n",
    "$k = 1$ . It contains the number of paths of length  \n",
    "$1$  between each pair of vertices.\n",
    "\n",
    "We will build the solution iteratively: Let's assume we know the answer for some  \n",
    "$k$ . Here we describe a method how we can construct the answer for  \n",
    "$k + 1$ . Denote by  \n",
    "$C_k$  the matrix for the case  \n",
    "$k$ , and by  \n",
    "$C_{k+1}$  the matrix we want to construct. With the following formula we can compute every entry of  \n",
    "$C_{k+1}$ :\n",
    "\n",
    " \n",
    " \n",
    " \n",
    "$$C_{k+1}[i][j] = \\sum_{p = 1}^{n} C_k[i][p] \\cdot G[p][j]$$ \n",
    "It is easy to see that the formula computes nothing other than the product of the matrices  \n",
    "$C_k$  and  \n",
    "$G$ :\n",
    "\n",
    " \n",
    "$$C_{k+1} = C_k \\cdot G$$ \n",
    "Thus the solution of the problem can be represented as follows:\n",
    "\n",
    "  \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "$$C_k = \\underbrace{G \\cdot G \\cdots G}_{k \\text{ times}} = G^k$$ \n",
    "It remains to note that the matrix products can be raised to a high power efficiently using Binary exponentiation. This gives a solution with  \n",
    "$O(n^3 \\log k)$  complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c266c-8f6e-4c5f-b451-12b34af8506e",
   "metadata": {},
   "source": [
    "## Shortest paths of a fixed length¶\n",
    "We are given a directed weighted graph  \n",
    "$G$  with  \n",
    "$n$  vertices and an integer  \n",
    "$k$ . For each pair of vertices  \n",
    "$(i, j)$  we have to find the length of the shortest path between  \n",
    "$i$  and  \n",
    "$j$  that consists of exactly  \n",
    "$k$  edges.\n",
    "\n",
    "We assume that the graph is specified by an adjacency matrix, i.e. via the matrix  \n",
    "$G[][]$  of size  \n",
    "$n \\times n$  where each element  \n",
    "$G[i][j]$  contains the length of the edges from the vertex  \n",
    "$i$  to the vertex  \n",
    "$j$ . If there is no edge between two vertices, then the corresponding element of the matrix will be assigned to infinity  \n",
    "$\\infty$ .\n",
    "\n",
    "It is obvious that in this form the adjacency matrix is the answer to the problem for  \n",
    "$k = 1$ . It contains the lengths of shortest paths between each pair of vertices, or  \n",
    "$\\infty$  if a path consisting of one edge doesn't exist.\n",
    "\n",
    "Again we can build the solution to the problem iteratively: Let's assume we know the answer for some  \n",
    "$k$ . We show how we can compute the answer for  \n",
    "$k+1$ . Let us denote  \n",
    "$L_k$  the matrix for  \n",
    "$k$  and  \n",
    "$L_{k+1}$  the matrix we want to build. Then the following formula computes each entry of  \n",
    "$L_{k+1}$ :\n",
    "\n",
    "  \n",
    " \n",
    " \n",
    "$$L_{k+1}[i][j] = \\min_{p = 1 \\ldots n} \\left(L_k[i][p] + G[p][j]\\right)$$ \n",
    "When looking closer at this formula, we can draw an analogy with the matrix multiplication: in fact the matrix  \n",
    "$L_k$  is multiplied by the matrix  \n",
    "$G$ , the only difference is that instead in the multiplication operation we take the minimum instead of the sum.\n",
    "\n",
    " \n",
    "$$L_{k+1} = L_k \\odot G,$$ \n",
    "where the operation  \n",
    "$\\odot$  is defined as follows:\n",
    "\n",
    "  \n",
    " \n",
    " \n",
    "$$A \\odot B = C~~\\Longleftrightarrow~~C_{i j} = \\min_{p = 1 \\ldots n}\\left(A_{i p} + B_{p j}\\right)$$ \n",
    "Thus the solution of the task can be represented using the modified multiplication:\n",
    "\n",
    "  \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "$$L_k = \\underbrace{G \\odot \\ldots \\odot G}_{k~\\text{times}} = G^{\\odot k}$$ \n",
    "It remains to note that we also can compute this exponentiation efficiently with Binary exponentiation, because the modified multiplication is obviously associative. So also this solution has  \n",
    "$O(n^3 \\log k)$  complexity.\n",
    "\n",
    "Generalization of the problems for paths with length up to  \n",
    "$k$ ¶\n",
    "The above solutions solve the problems for a fixed  \n",
    "$k$ . However the solutions can be adapted for solving problems for which the paths are allowed to contain no more than  \n",
    "$k$  edges.\n",
    "\n",
    "This can be done by slightly modifying the input graph.\n",
    "\n",
    "We duplicate each vertex: for each vertex  \n",
    "$v$  we create one more vertex  \n",
    "$v'$  and add the edge  \n",
    "$(v, v')$  and the loop  \n",
    "$(v', v')$ . The number of paths between  \n",
    "$i$  and  \n",
    "$j$  with at most  \n",
    "$k$  edges is the same number as the number of paths between  \n",
    "$i$  and  \n",
    "$j'$  with exactly  \n",
    "$k + 1$  edges, since there is a bijection that maps every path  \n",
    "$[p_0 = i,~p_1,~\\ldots,~p_{m-1},~p_m = j]$  of length  \n",
    "$m \\le k$  to the path  \n",
    "$[p_0 = i,~p_1,~\\ldots,~p_{m-1},~p_m = j, j', \\ldots, j']$  of length  \n",
    "$k + 1$ .\n",
    "\n",
    "The same trick can be applied to compute the shortest paths with at most  \n",
    "$k$  edges. We again duplicate each vertex and add the two mentioned edges with weight  \n",
    "$0$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae8cd0-58ad-4688-baa9-06f71331dbf0",
   "metadata": {},
   "source": [
    "# Floyd-Warshall Algorithm\n",
    "Given a directed or an undirected weighted graph  \n",
    "$G$  with  \n",
    "$n$  vertices. The task is to find the length of the shortest path  \n",
    "$d_{ij}$  between each pair of vertices  \n",
    "$i$  and  \n",
    "$j$ .\n",
    "\n",
    "The graph may have negative weight edges, but no negative weight cycles.\n",
    "\n",
    "If there is such a negative cycle, you can just traverse this cycle over and over, in each iteration making the cost of the path smaller. So you can make certain paths arbitrarily small, or in other words that shortest path is undefined. That automatically means that an undirected graph cannot have any negative weight edges, as such an edge forms already a negative cycle as you can move back and forth along that edge as long as you like.\n",
    "\n",
    "This algorithm can also be used to detect the presence of negative cycles. The graph has a negative cycle if at the end of the algorithm, the distance from a vertex  \n",
    "$v$  to itself is negative.\n",
    "\n",
    "This algorithm has been simultaneously published in articles by Robert Floyd and Stephen Warshall in 1962. However, in 1959, Bernard Roy published essentially the same algorithm, but its publication went unnoticed.\n",
    "\n",
    "## Description of the algorithm\n",
    "The key idea of the algorithm is to partition the process of finding the shortest path between any two vertices to several incremental phases.\n",
    "\n",
    "Let us number the vertices starting from 1 to  \n",
    "$n$ . The matrix of distances is  \n",
    "$d[ ][ ]$ .\n",
    "\n",
    "Before  \n",
    "$k$ -th phase ( \n",
    "$k = 1 \\dots n$ ),  \n",
    "$d[i][j]$  for any vertices  \n",
    "$i$  and  \n",
    "$j$  stores the length of the shortest path between the vertex  \n",
    "$i$  and vertex  \n",
    "$j$ , which contains only the vertices  \n",
    "$\\{1, 2, ..., k-1\\}$  as internal vertices in the path.\n",
    "\n",
    "In other words, before  \n",
    "$k$ -th phase the value of  \n",
    "$d[i][j]$  is equal to the length of the shortest path from vertex  \n",
    "$i$  to the vertex  \n",
    "$j$ , if this path is allowed to enter only the vertex with numbers smaller than  \n",
    "$k$  (the beginning and end of the path are not restricted by this property).\n",
    "\n",
    "It is easy to make sure that this property holds for the first phase. For  \n",
    "$k = 0$ , we can fill matrix with  \n",
    "$d[i][j] = w_{i j}$  if there exists an edge between  \n",
    "$i$  and  \n",
    "$j$  with weight  \n",
    "$w_{i j}$  and  \n",
    "$d[i][j] = \\infty$  if there doesn't exist an edge. In practice  \n",
    "$\\infty$  will be some high value. As we shall see later, this is a requirement for the algorithm.\n",
    "\n",
    "Suppose now that we are in the  \n",
    "$k$ -th phase, and we want to compute the matrix  \n",
    "$d[ ][ ]$  so that it meets the requirements for the  \n",
    "$(k + 1)$ -th phase. We have to fix the distances for some vertices pairs  \n",
    "$(i, j)$ . There are two fundamentally different cases:\n",
    "\n",
    "The shortest way from the vertex  \n",
    "$i$  to the vertex  \n",
    "$j$  with internal vertices from the set  \n",
    "$\\{1, 2, \\dots, k\\}$  coincides with the shortest path with internal vertices from the set  \n",
    "$\\{1, 2, \\dots, k-1\\}$ .\n",
    "\n",
    "In this case,  \n",
    "$d[i][j]$  will not change during the transition.\n",
    "\n",
    "The shortest path with internal vertices from  \n",
    "$\\{1, 2, \\dots, k\\}$  is shorter.\n",
    "\n",
    "This means that the new, shorter path passes through the vertex  \n",
    "$k$ . This means that we can split the shortest path between  \n",
    "$i$  and  \n",
    "$j$  into two paths: the path between  \n",
    "$i$  and  \n",
    "$k$ , and the path between  \n",
    "$k$  and  \n",
    "$j$ . It is clear that both this paths only use internal vertices of  \n",
    "$\\{1, 2, \\dots, k-1\\}$  and are the shortest such paths in that respect. Therefore we already have computed the lengths of those paths before, and we can compute the length of the shortest path between  \n",
    "$i$  and  \n",
    "$j$  as  \n",
    "$d[i][k] + d[k][j]$ .\n",
    "\n",
    "Combining these two cases we find that we can recalculate the length of all pairs  \n",
    "$(i, j)$  in the  \n",
    "$k$ -th phase in the following way:\n",
    "\n",
    " \n",
    "$$d_{\\text{new}}[i][j] = min(d[i][j], d[i][k] + d[k][j])$$ \n",
    "Thus, all the work that is required in the  \n",
    "$k$ -th phase is to iterate over all pairs of vertices and recalculate the length of the shortest path between them. As a result, after the  \n",
    "$n$ -th phase, the value  \n",
    "$d[i][j]$  in the distance matrix is the length of the shortest path between  \n",
    "$i$  and  \n",
    "$j$ , or is  \n",
    "$\\infty$  if the path between the vertices  \n",
    "$i$  and  \n",
    "$j$  does not exist.\n",
    "\n",
    "A last remark - we don't need to create a separate distance matrix  \n",
    "$d_{\\text{new}}[ ][ ]$  for temporarily storing the shortest paths of the  \n",
    "$k$ -th phase, i.e. all changes can be made directly in the matrix  \n",
    "$d[ ][ ]$  at any phase. In fact at any  \n",
    "$k$ -th phase we are at most improving the distance of any path in the distance matrix, hence we cannot worsen the length of the shortest path for any pair of the vertices that are to be processed in the  \n",
    "$(k+1)$ -th phase or later.\n",
    "\n",
    "The time complexity of this algorithm is obviously  \n",
    "$O(n^3)$ .\n",
    "\n",
    "## Implementation\n",
    "Let  \n",
    "$d[][]$  is a 2D array of size  \n",
    "$n \\times n$ , which is filled according to the  \n",
    "$0$ -th phase as explained earlier. Also we will set  \n",
    "$d[i][i] = 0$  for any  \n",
    "$i$  at the  \n",
    "$0$ -th phase.\n",
    "\n",
    "Then the algorithm is implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44d09a-108c-4d91-a5a9-13b42be0b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (int k = 0; k < n; ++k) {\n",
    "    for (int i = 0; i < n; ++i) {\n",
    "        for (int j = 0; j < n; ++j) {\n",
    "            d[i][j] = min(d[i][j], d[i][k] + d[k][j]); \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb95852f-3a11-4174-a606-1e433bc43a43",
   "metadata": {},
   "source": [
    "It is assumed that if there is no edge between any two vertices  \n",
    "$i$  and  \n",
    "$j$ , then the matrix at  \n",
    "$d[i][j]$  contains a large number (large enough so that it is greater than the length of any path in this graph). Then this edge will always be unprofitable to take, and the algorithm will work correctly.\n",
    "\n",
    "However if there are negative weight edges in the graph, special measures have to be taken. Otherwise the resulting values in matrix may be of the form  \n",
    "$\\infty - 1$ ,  \n",
    "$\\infty - 2$ , etc., which, of course, still indicates that between the respective vertices doesn't exist a path. Therefore, if the graph has negative weight edges, it is better to write the Floyd-Warshall algorithm in the following way, so that it does not perform transitions using paths that don't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab2460a-6c31-493a-8e21-d81d3ab1bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (int k = 0; k < n; ++k) {\n",
    "    for (int i = 0; i < n; ++i) {\n",
    "        for (int j = 0; j < n; ++j) {\n",
    "            if (d[i][k] < INF && d[k][j] < INF)\n",
    "                d[i][j] = min(d[i][j], d[i][k] + d[k][j]); \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56827b5f-311f-40ef-a223-4d61fb812aec",
   "metadata": {},
   "source": [
    "## Retrieving the sequence of vertices in the shortest path¶\n",
    "It is easy to maintain additional information with which it will be possible to retrieve the shortest path between any two given vertices in the form of a sequence of vertices.\n",
    "\n",
    "For this, in addition to the distance matrix  \n",
    "$d[ ][ ]$ , a matrix of ancestors  \n",
    "$p[ ][ ]$  must be maintained, which will contain the number of the phase where the shortest distance between two vertices was last modified. It is clear that the number of the phase is nothing more than a vertex in the middle of the desired shortest path. Now we just need to find the shortest path between vertices  \n",
    "$i$  and  \n",
    "$p[i][j]$ , and between  \n",
    "$p[i][j]$  and  \n",
    "$j$ . This leads to a simple recursive reconstruction algorithm of the shortest path.\n",
    "\n",
    "The case of real weights¶\n",
    "If the weights of the edges are not integer but real, it is necessary to take the errors, which occur when working with float types, into account.\n",
    "\n",
    "The Floyd-Warshall algorithm has the unpleasant effect, that the errors accumulate very quickly. In fact if there is an error in the first phase of  \n",
    "$\\delta$ , this error may propagate to the second iteration as  \n",
    "$2 \\delta$ , to the third iteration as  \n",
    "$4 \\delta$ , and so on.\n",
    "\n",
    "To avoid this the algorithm can be modified to take the error (EPS =  \n",
    "$\\delta$ ) into account by using following comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59488c5e-4204-428e-9e26-b1690104be58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
